<Project Sdk="Microsoft.NET.Sdk">
  <PropertyGroup>
    <TargetFrameworks>netstandard2.0;net6.0;net8.0</TargetFrameworks>
    <RootNamespace>LLama</RootNamespace>
    <Nullable>enable</Nullable>
    <LangVersion>12</LangVersion>
    <Platforms>AnyCPU;x64;Arm64</Platforms>
    <AllowUnsafeBlocks>True</AllowUnsafeBlocks>

    <Version>0.13.0</Version>
    <Authors>Rinne, Martin Evans, jlsantiago and all the other contributors in https://github.com/SciSharp/LLamaSharp/graphs/contributors.</Authors>
    <Company>SciSharp STACK</Company>
    <GeneratePackageOnBuild>true</GeneratePackageOnBuild>
    <Copyright>MIT, SciSharp STACK $([System.DateTime]::UtcNow.ToString(yyyy))</Copyright>
    <RepositoryUrl>https://github.com/SciSharp/LLamaSharp</RepositoryUrl>
    <RepositoryType>git</RepositoryType>
    <PackageIconUrl>https://avatars3.githubusercontent.com/u/44989469?s=200&amp;v=4</PackageIconUrl>
    <PackageTags>LLama, LLM, GPT, ChatGPT, NLP, AI, Chat Bot, SciSharp</PackageTags>
    <Description>
      LLamaSharp is a cross-platform library to run ðŸ¦™LLaMA/LLaVA model (and others) in your local device. 
      Based on [llama.cpp](https://github.com/ggerganov/llama.cpp), inference with LLamaSharp is efficient on both CPU and GPU. 
      With the higher-level APIs and RAG support, it's convenient to deploy LLM (Large Language Model) in your application with LLamaSharp.
    </Description>
    <PackageReleaseNotes>
      Updated llama.cpp version to include better support for LLama3 tokenization.
    </PackageReleaseNotes>
    <PackageLicenseExpression>MIT</PackageLicenseExpression>
    <PackageOutputPath>$(SolutionDir)/packages</PackageOutputPath>
    <Platforms>AnyCPU;x64;Arm64</Platforms>
    <PackageId>LLamaSharp</PackageId>
    <Configurations>Debug;Release;GPU</Configurations>
    <GenerateAssemblyInfo>false</GenerateAssemblyInfo>
  </PropertyGroup>

  <PropertyGroup>
    <PackageReadmeFile>README.md</PackageReadmeFile>
    <GenerateDocumentationFile>True</GenerateDocumentationFile>
  </PropertyGroup>

  <ItemGroup>
    <None Include="..\README.md" Pack="true" PackagePath="\" />
  </ItemGroup>

  <ItemGroup Condition="'$(TargetFramework)' == 'netstandard2.0'">
    <PackageReference Include="IsExternalInit" Version="1.0.3" PrivateAssets="all" />
    <PackageReference Include="System.Memory" Version="4.5.5" PrivateAssets="all" />
    <PackageReference Include="System.Linq.Async" Version="6.0.1" />
    <PackageReference Include="System.Text.Json" Version="8.0.3" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="8.0.1" />
  </ItemGroup>

</Project>
