<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFrameworks>netstandard2.0;net6.0;net7.0</TargetFrameworks>
    <RootNamespace>LLama</RootNamespace>
    <Nullable>enable</Nullable>
    <LangVersion>10</LangVersion>
    <Platforms>AnyCPU;x64</Platforms>
    <AllowUnsafeBlocks>True</AllowUnsafeBlocks>

    <Version>0.3.0</Version>
    <Authors>Yaohui Liu, Haiping Chen</Authors>
    <Company>SciSharp STACK</Company>
    <GeneratePackageOnBuild>true</GeneratePackageOnBuild>
    <Copyright>MIT, SciSharp STACK $([System.DateTime]::UtcNow.ToString(yyyy))</Copyright>
    <RepositoryUrl>https://github.com/SciSharp/LLamaSharp</RepositoryUrl>
    <RepositoryType>git</RepositoryType>
    <PackageIconUrl>https://avatars3.githubusercontent.com/u/44989469?s=200&amp;v=4</PackageIconUrl>
    <PackageTags>LLama, LLM, GPT, ChatGPT, NLP, AI, Chat Bot, SciSharp</PackageTags>
    <Description>
      The .NET binding of LLama.cpp, providing APIs to run the model and deploy it on Web. For model weights to run, please go to https://github.com/SciSharp/LLamaSharp for more information.
    </Description>
    <PackageReleaseNotes>
      LLamaSharp 0.3.0 supports loading and saving session state, tokenization and detokenization. Besides, since 0.3.0, `LLamaModelV1` is dropped.
    </PackageReleaseNotes>
    <PackageLicenseExpression>MIT</PackageLicenseExpression>
    <PackageOutputPath>packages</PackageOutputPath>
    <Platforms>AnyCPU;x64</Platforms>
    <PackageId>LLamaSharp</PackageId>
    <Configurations>Debug;Release;GPU</Configurations>
  </PropertyGroup>

  <PropertyGroup>
    <PackageReadmeFile>README.md</PackageReadmeFile>
  </PropertyGroup>

  <ItemGroup>
    <None Include="..\README.md" Pack="true" PackagePath="\" />
  </ItemGroup>

  <ItemGroup Condition="'$(TargetFramework)' == 'netstandard2.0'">
    <PackageReference Include="IsExternalInit" Version="1.0.3" PrivateAssets="all" />
    <PackageReference Include="System.Memory" Version="4.5.4" PrivateAssets="all" />
  </ItemGroup>

  <ItemGroup>
    <None Include="runtimes/libllama.dll">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama.dll</Link>
    </None>
    <None Include="runtimes/libllama-cuda11.dll">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama-cuda11.dll</Link>
    </None>
    <None Include="runtimes/libllama-cuda12.dll">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama-cuda12.dll</Link>
    </None>
    <None Include="runtimes/libllama.so">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama.so</Link>
    </None>
    <None Include="runtimes/libllama-cuda11.so">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama-cuda11.so</Link>
    </None>
    <None Include="runtimes/libllama-cuda12.so">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
      <Link>libllama-cuda12.so</Link>
    </None>
  </ItemGroup>

</Project>
