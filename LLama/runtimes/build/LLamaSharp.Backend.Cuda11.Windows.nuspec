<?xml version="1.0" encoding="utf-8"?>
<package >
    <metadata>
        <id>LLamaSharp.Backend.Cuda11.Windows</id>
        <version>$version$</version>
        <title>LLamaSharp.Backend.Cuda11.Windows</title>
        <authors>llama.cpp Authors</authors>
        <requireLicenseAcceptance>false</requireLicenseAcceptance>
        <license type="expression">MIT</license>
        <icon>icon512.png</icon>
        <projectUrl>https://github.com/SciSharp/LLamaSharp</projectUrl>
        <description>LLamaSharp.Backend.Cuda11.Windows contains the Windows binaries for LLamaSharp with Cuda11 support.</description>
        <releaseNotes></releaseNotes>
        <copyright>Copyright 2023 The llama.cpp Authors. All rights reserved.</copyright>
        <tags>LLamaSharp LLama LLM GPT AI ChatBot SciSharp</tags>

        <dependencies>
            <dependency id="LLamaSharp.Backend.Cpu" version="$version$" />
        </dependencies>
    </metadata>

    <files>
        <file src="LLamaSharpBackend.props" target="build/netstandard2.0/LLamaSharp.Backend.Cuda11.props" />

        <file src="runtimes/deps/cu11.7.1/ggml.dll" target="runtimes\win-x64\native\cuda11\ggml.dll" />
        <file src="runtimes/deps/cu11.7.1/ggml-base.dll" target="runtimes\win-x64\native\cuda11\ggml-base.dll" />
        <file src="runtimes/deps/cu11.7.1/ggml-cuda.dll" target="runtimes\win-x64\native\cuda11\ggml-cuda.dll" />

        <file src="runtimes/deps/cu11.7.1/llama.dll" target="runtimes\win-x64\native\cuda11\llama.dll" />
        <file src="runtimes/deps/cu11.7.1/llava_shared.dll" target="runtimes\win-x64\native\cuda11\llava_shared.dll" />
        
        <file src="icon512.png" target="icon512.png" />
    </files>
</package>
