
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../llama.native.llavaimageembed/">
      
      
        <link rel="next" href="../llama.native.nativelibraryconfig/">
      
      <link rel="icon" href="../../media/icon128.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.20">
    
    
      
        <title>llama.native.nativeapi - LLamaSharp Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,700,700i%7CFira+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Fira Sans";--md-code-font:"Fira Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css?v=14">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#nativeapi" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLamaSharp Documentation" class="md-header__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 9h5.5L13 3.5V9M6 2h8l6 6v12a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4c0-1.11.89-2 2-2m9 16v-2H6v2h9m3-4v-2H6v2h12Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLamaSharp Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              llama.native.nativeapi
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLamaSharp Documentation" class="md-nav__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 9h5.5L13 3.5V9M6 2h8l6 6v12a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4c0-1.11.89-2 2-2m9 16v-2H6v2h9m3-4v-2H6v2h12Z"/></svg>

    </a>
    LLamaSharp Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../QuickStart/" class="md-nav__link">
        Quick Start
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../Architecture/" class="md-nav__link">
        Architecture
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../FAQ/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../ContributingGuide/" class="md-nav__link">
        Contributing Guide
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/NativeLibraryConfig/" class="md-nav__link">
        Configure the native library loading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/Executors/" class="md-nav__link">
        Use executors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/ChatSession/" class="md-nav__link">
        Use ChatSession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/UnderstandLLamaContext/" class="md-nav__link">
        Understand LLamaContext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/Quantization/" class="md-nav__link">
        Quantize the model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          Advanced Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Advanced Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../AdvancedTutorials/CustomizeNativeLibraryLoading/" class="md-nav__link">
        Customize the native library loading
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          Integrations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Integrations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/semantic-kernel/" class="md-nav__link">
        semantic-kernel integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/kernel-memory/" class="md-nav__link">
        kernel-memory integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/BotSharp.md" class="md-nav__link">
        BotSharp integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/Langchain.md" class="md-nav__link">
        Langchain integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
      
      
      
        <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorFork/" class="md-nav__link">
        Bacthed executor - multi-output to one input
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorGuidance/" class="md-nav__link">
        Batched executor - basic guidance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorRewind/" class="md-nav__link">
        Batched executor - rewinding to an earlier state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatChineseGB2312/" class="md-nav__link">
        Chinese LLM - with GB2312 encoding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionStripRoleName/" class="md-nav__link">
        ChatSession - stripping role names
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithHistory/" class="md-nav__link">
        ChatSession - with history
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRestart/" class="md-nav__link">
        ChatSession - restarting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRoleName/" class="md-nav__link">
        ChatSession - Basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/CodingAssistant/" class="md-nav__link">
        Coding assistant
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GrammarJsonResponse/" class="md-nav__link">
        Grammar - json response
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InstructModeExecute/" class="md-nav__link">
        Instruct executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InteractiveModeExecute/" class="md-nav__link">
        Interactive executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemory/" class="md-nav__link">
        Kernel memory integration - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemorySaveAndLoad/" class="md-nav__link">
        Kernel-memory - save & load
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LLavaInteractiveModeExecute/" class="md-nav__link">
        LLaVA - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveSession/" class="md-nav__link">
        ChatSession - load & save
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveState/" class="md-nav__link">
        Executor - save/load state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/QuantizeModel/" class="md-nav__link">
        Quantization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelChat/" class="md-nav__link">
        Semantic-kernel - chat
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelMemory/" class="md-nav__link">
        Semantic-kernel - with kernel-memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelPrompt/" class="md-nav__link">
        Semantic-kernel - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/StatelessModeExecute/" class="md-nav__link">
        Stateless executor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/TalkToYourself/" class="md-nav__link">
        Talk to yourself
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" checked>
      
      
      
        <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.adaptercollection/" class="md-nav__link">
        llama.abstractions.adaptercollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.icontextparams/" class="md-nav__link">
        llama.abstractions.icontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.ihistorytransform/" class="md-nav__link">
        llama.abstractions.ihistorytransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.iinferenceparams/" class="md-nav__link">
        llama.abstractions.iinferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.illamaexecutor/" class="md-nav__link">
        llama.abstractions.illamaexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.illamaparams/" class="md-nav__link">
        llama.abstractions.illamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.imodelparams/" class="md-nav__link">
        llama.abstractions.imodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.itextstreamtransform/" class="md-nav__link">
        llama.abstractions.itextstreamtransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.itexttransform/" class="md-nav__link">
        llama.abstractions.itexttransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.loraadapter/" class="md-nav__link">
        llama.abstractions.loraadapter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.metadataoverride/" class="md-nav__link">
        llama.abstractions.metadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.metadataoverrideconverter/" class="md-nav__link">
        llama.abstractions.metadataoverrideconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.tensorsplitscollection/" class="md-nav__link">
        llama.abstractions.tensorsplitscollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.tensorsplitscollectionconverter/" class="md-nav__link">
        llama.abstractions.tensorsplitscollectionconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.antipromptprocessor/" class="md-nav__link">
        llama.antipromptprocessor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.alreadypromptedconversationexception/" class="md-nav__link">
        llama.batched.alreadypromptedconversationexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.batchedexecutor/" class="md-nav__link">
        llama.batched.batchedexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotforkwhilerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotforkwhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotmodifywhilerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotmodifywhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotsamplerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotsamplerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotsamplerequirespromptexception/" class="md-nav__link">
        llama.batched.cannotsamplerequirespromptexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.conversation/" class="md-nav__link">
        llama.batched.conversation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.conversationextensions/" class="md-nav__link">
        llama.batched.conversationextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.experimentalbatchedexecutorexception/" class="md-nav__link">
        llama.batched.experimentalbatchedexecutorexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.chatsession-1/" class="md-nav__link">
        llama.chatsession-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.chatsession/" class="md-nav__link">
        llama.chatsession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.authorrole/" class="md-nav__link">
        llama.common.authorrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.chathistory/" class="md-nav__link">
        llama.common.chathistory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.fixedsizequeue-1/" class="md-nav__link">
        llama.common.fixedsizequeue-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.inferenceparams/" class="md-nav__link">
        llama.common.inferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.mirostattype/" class="md-nav__link">
        llama.common.mirostattype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.modelparams/" class="md-nav__link">
        llama.common.modelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectedname/" class="md-nav__link">
        llama.exceptions.grammarexpectedname
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectednext/" class="md-nav__link">
        llama.exceptions.grammarexpectednext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectedprevious/" class="md-nav__link">
        llama.exceptions.grammarexpectedprevious
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarformatexception/" class="md-nav__link">
        llama.exceptions.grammarformatexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedcharaltelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharaltelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedcharrngelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharrngelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedendelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedendelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedendofinput/" class="md-nav__link">
        llama.exceptions.grammarunexpectedendofinput
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedhexcharscount/" class="md-nav__link">
        llama.exceptions.grammarunexpectedhexcharscount
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunknownescapecharacter/" class="md-nav__link">
        llama.exceptions.grammarunknownescapecharacter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.llamadecodeerror/" class="md-nav__link">
        llama.exceptions.llamadecodeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.loadweightsfailedexception/" class="md-nav__link">
        llama.exceptions.loadweightsfailedexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.runtimeerror/" class="md-nav__link">
        llama.exceptions.runtimeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.extensions.icontextparamsextensions/" class="md-nav__link">
        llama.extensions.icontextparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.extensions.imodelparamsextensions/" class="md-nav__link">
        llama.extensions.imodelparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.grammars.grammar/" class="md-nav__link">
        llama.grammars.grammar
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.grammars.grammarrule/" class="md-nav__link">
        llama.grammars.grammarrule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.ichatmodel/" class="md-nav__link">
        llama.ichatmodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamacache/" class="md-nav__link">
        llama.llamacache
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaembedder/" class="md-nav__link">
        llama.llamaembedder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamamodel/" class="md-nav__link">
        llama.llamamodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamamodelv1/" class="md-nav__link">
        llama.llamamodelv1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaparams/" class="md-nav__link">
        llama.llamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaquantizer/" class="md-nav__link">
        llama.llamaquantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamastate/" class="md-nav__link">
        llama.llamastate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamatransforms/" class="md-nav__link">
        llama.llamatransforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llavaweights/" class="md-nav__link">
        llama.llavaweights
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.decoderesult/" class="md-nav__link">
        llama.native.decoderesult
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.ggmltype/" class="md-nav__link">
        llama.native.ggmltype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.gpusplitmode/" class="md-nav__link">
        llama.native.gpusplitmode
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabatch/" class="md-nav__link">
        llama.native.llamabatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabeamsstate/" class="md-nav__link">
        llama.native.llamabeamsstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabeamview/" class="md-nav__link">
        llama.native.llamabeamview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamachatmessage/" class="md-nav__link">
        llama.native.llamachatmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamacontextparams/" class="md-nav__link">
        llama.native.llamacontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaftype/" class="md-nav__link">
        llama.native.llamaftype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamagrammarelement/" class="md-nav__link">
        llama.native.llamagrammarelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamagrammarelementtype/" class="md-nav__link">
        llama.native.llamagrammarelementtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheview/" class="md-nav__link">
        llama.native.llamakvcacheview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheviewcell/" class="md-nav__link">
        llama.native.llamakvcacheviewcell
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheviewsafehandle/" class="md-nav__link">
        llama.native.llamakvcacheviewsafehandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaloglevel/" class="md-nav__link">
        llama.native.llamaloglevel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelkvoverridetype/" class="md-nav__link">
        llama.native.llamamodelkvoverridetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelmetadataoverride/" class="md-nav__link">
        llama.native.llamamodelmetadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelparams/" class="md-nav__link">
        llama.native.llamamodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelquantizeparams/" class="md-nav__link">
        llama.native.llamamodelquantizeparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamanativebatch/" class="md-nav__link">
        llama.native.llamanativebatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamapoolingtype/" class="md-nav__link">
        llama.native.llamapoolingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamapos/" class="md-nav__link">
        llama.native.llamapos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaropetype/" class="md-nav__link">
        llama.native.llamaropetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaseqid/" class="md-nav__link">
        llama.native.llamaseqid
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatoken/" class="md-nav__link">
        llama.native.llamatoken
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendata/" class="md-nav__link">
        llama.native.llamatokendata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendataarray/" class="md-nav__link">
        llama.native.llamatokendataarray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendataarraynative/" class="md-nav__link">
        llama.native.llamatokendataarraynative
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokentype/" class="md-nav__link">
        llama.native.llamatokentype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamavocabtype/" class="md-nav__link">
        llama.native.llamavocabtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llavaimageembed/" class="md-nav__link">
        llama.native.llavaimageembed
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          llama.native.nativeapi
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        llama.native.nativeapi
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_mirostatsafellamacontexthandle-llamatokendataarraynative-single-single-int32-single" class="md-nav__link">
    llama_sample_token_mirostat(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Int32, Single&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_mirostat(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Int32, Single&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_mirostat_v2safellamacontexthandle-llamatokendataarraynative-single-single-single" class="md-nav__link">
    llama_sample_token_mirostat_v2(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_mirostat_v2(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Single&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_greedysafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_token_greedy(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_greedy(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tokensafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_token(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingsg__llama_get_embeddings_native30_0safellamacontexthandle" class="md-nav__link">
    &lt;llama_get_embeddings&gt;g__llama_get_embeddings_native|30_0(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="<llama_get_embeddings>g__llama_get_embeddings_native|30_0(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_pieceg__llama_token_to_piece_native44_0safellamamodelhandle-llamatoken-byte-int32" class="md-nav__link">
    &lt;llama_token_to_piece&gt;g__llama_token_to_piece_native|44_0(SafeLlamaModelHandle, LLamaToken, Byte*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="<llama_token_to_piece>g__llama_token_to_piece_native|44_0(SafeLlamaModelHandle, LLamaToken, Byte*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tryloadlibrariesg__tryload84_0string" class="md-nav__link">
    &lt;TryLoadLibraries&gt;g__TryLoad|84_0(String)
  </a>
  
    <nav class="md-nav" aria-label="<TryLoadLibraries>g__TryLoad|84_0(String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tryloadlibrariesg__tryfindpath84_1string-c__displayclass84_0" class="md-nav__link">
    &lt;TryLoadLibraries&gt;g__TryFindPath|84_1(String, &lt;&gt;c__DisplayClass84_0&amp;)
  </a>
  
    <nav class="md-nav" aria-label="<TryLoadLibraries>g__TryFindPath|84_1(String, <>c__DisplayClass84_0&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_n_threadssafellamacontexthandle-uint32-uint32" class="md-nav__link">
    llama_set_n_threads(SafeLLamaContextHandle, UInt32, UInt32)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_n_threads(SafeLLamaContextHandle, UInt32, UInt32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_vocab_typesafellamamodelhandle" class="md-nav__link">
    llama_vocab_type(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_vocab_type(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_rope_typesafellamamodelhandle" class="md-nav__link">
    llama_rope_type(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_rope_type(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_initllamagrammarelement-uint64-uint64" class="md-nav__link">
    llama_grammar_init(LLamaGrammarElement, UInt64, UInt64)**
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_init(LLamaGrammarElement, UInt64, UInt64)**">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_freeintptr" class="md-nav__link">
    llama_grammar_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_copysafellamagrammarhandle" class="md-nav__link">
    llama_grammar_copy(SafeLLamaGrammarHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_copy(SafeLLamaGrammarHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_grammarsafellamacontexthandle-llamatokendataarraynative-safellamagrammarhandle" class="md-nav__link">
    llama_sample_grammar(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, SafeLLamaGrammarHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_grammar(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, SafeLLamaGrammarHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_accept_tokensafellamacontexthandle-safellamagrammarhandle-llamatoken" class="md-nav__link">
    llama_grammar_accept_token(SafeLLamaContextHandle, SafeLLamaGrammarHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_accept_token(SafeLLamaContextHandle, SafeLLamaGrammarHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" class="md-nav__link">
    llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" class="md-nav__link">
    llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" class="md-nav__link">
    llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_freeintptr" class="md-nav__link">
    llava_image_embed_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" class="md-nav__link">
    llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantizestring-string-llamamodelquantizeparams" class="md-nav__link">
    llama_model_quantize(String, String, LLamaModelQuantizeParams*)
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize(String, String, LLamaModelQuantizeParams*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_repetition_penaltiessafellamacontexthandle-llamatokendataarraynative-llamatoken-uint64-single-single-single" class="md-nav__link">
    llama_sample_repetition_penalties(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, LLamaToken*, UInt64, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_repetition_penalties(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, LLamaToken*, UInt64, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_apply_guidancesafellamacontexthandle-spansingle-readonlyspansingle-single" class="md-nav__link">
    llama_sample_apply_guidance(SafeLLamaContextHandle, Span&lt;Single&gt;, ReadOnlySpan&lt;Single&gt;, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_apply_guidance(SafeLLamaContextHandle, Span<Single>, ReadOnlySpan<Single>, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_apply_guidancesafellamacontexthandle-single-single-single" class="md-nav__link">
    llama_sample_apply_guidance(SafeLLamaContextHandle, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_apply_guidance(SafeLLamaContextHandle, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_softmaxsafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_softmax(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_softmax(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_top_ksafellamacontexthandle-llamatokendataarraynative-int32-uint64" class="md-nav__link">
    llama_sample_top_k(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Int32, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_top_k(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Int32, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_top_psafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_top_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_top_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_min_psafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_min_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_min_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tail_freesafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_tail_free(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_tail_free(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_30" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-single-single" class="md-nav__link">
    llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_31" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tempsafellamacontexthandle-llamatokendataarraynative-single" class="md-nav__link">
    llama_sample_temp(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_temp(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_32" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingssafellamacontexthandle" class="md-nav__link">
    llama_get_embeddings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_33" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_apply_templatesafellamamodelhandle-char-llamachatmessage-intptr-boolean-char-int32" class="md-nav__link">
    llama_chat_apply_template(SafeLlamaModelHandle, Char, LLamaChatMessage, IntPtr, Boolean, Char*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_apply_template(SafeLlamaModelHandle, Char, LLamaChatMessage, IntPtr, Boolean, Char*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_34" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_bossafellamamodelhandle" class="md-nav__link">
    llama_token_bos(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_bos(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_35" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_eossafellamamodelhandle" class="md-nav__link">
    llama_token_eos(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_eos(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_36" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_nlsafellamamodelhandle" class="md-nav__link">
    llama_token_nl(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_nl(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_37" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_add_bos_tokensafellamamodelhandle" class="md-nav__link">
    llama_add_bos_token(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_add_bos_token(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_38" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_add_eos_tokensafellamamodelhandle" class="md-nav__link">
    llama_add_eos_token(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_add_eos_token(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_39" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_prefixsafellamamodelhandle" class="md-nav__link">
    llama_token_prefix(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_prefix(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_40" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_middlesafellamamodelhandle" class="md-nav__link">
    llama_token_middle(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_middle(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_41" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_suffixsafellamamodelhandle" class="md-nav__link">
    llama_token_suffix(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_suffix(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_42" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_eotsafellamamodelhandle" class="md-nav__link">
    llama_token_eot(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_eot(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_43" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_timingssafellamacontexthandle" class="md-nav__link">
    llama_print_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_print_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_44" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_reset_timingssafellamacontexthandle" class="md-nav__link">
    llama_reset_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_reset_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_45" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_system_info" class="md-nav__link">
    llama_print_system_info()
  </a>
  
    <nav class="md-nav" aria-label="llama_print_system_info()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_piecesafellamamodelhandle-llamatoken-spanbyte" class="md-nav__link">
    llama_token_to_piece(SafeLlamaModelHandle, LLamaToken, Span&lt;Byte&gt;)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_to_piece(SafeLlamaModelHandle, LLamaToken, Span<Byte>)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_46" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_tokenizesafellamamodelhandle-byte-int32-llamatoken-int32-boolean-boolean" class="md-nav__link">
    llama_tokenize(SafeLlamaModelHandle, Byte, Int32, LLamaToken, Int32, Boolean, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_tokenize(SafeLlamaModelHandle, Byte, Int32, LLamaToken, Int32, Boolean, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_47" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_30" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_log_setllamalogcallback" class="md-nav__link">
    llama_log_set(LLamaLogCallback)
  </a>
  
    <nav class="md-nav" aria-label="llama_log_set(LLamaLogCallback)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_48" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_clearsafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_clear(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_clear(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_49" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_cache_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_50" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_cpsafellamacontexthandle-llamaseqid-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_cache_seq_cp(SafeLLamaContextHandle, LLamaSeqId, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_cp(SafeLLamaContextHandle, LLamaSeqId, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_51" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_keepsafellamacontexthandle-llamaseqid" class="md-nav__link">
    llama_kv_cache_seq_keep(SafeLLamaContextHandle, LLamaSeqId)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_keep(SafeLLamaContextHandle, LLamaSeqId)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_52" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_addsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" class="md-nav__link">
    llama_kv_cache_seq_add(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_add(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_53" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_divsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" class="md-nav__link">
    llama_kv_cache_seq_div(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_div(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_54" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_pos_maxsafellamacontexthandle-llamaseqid" class="md-nav__link">
    llama_kv_cache_seq_pos_max(SafeLLamaContextHandle, LLamaSeqId)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_pos_max(SafeLLamaContextHandle, LLamaSeqId)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_55" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_31" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_defragsafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_defrag(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_defrag(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_56" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_32" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_updatesafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_update(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_update(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_57" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_initint32-int32-int32" class="md-nav__link">
    llama_batch_init(Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_init(Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_58" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_33" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_freellamanativebatch" class="md-nav__link">
    llama_batch_free(LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_free(LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_59" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_decodesafellamacontexthandle-llamanativebatch" class="md-nav__link">
    llama_decode(SafeLLamaContextHandle, LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_decode(SafeLLamaContextHandle, LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_60" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_34" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_initsafellamacontexthandle-int32" class="md-nav__link">
    llama_kv_cache_view_init(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_init(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_61" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_35" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_freellamakvcacheview" class="md-nav__link">
    llama_kv_cache_view_free(LLamaKvCacheView&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_free(LLamaKvCacheView&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_62" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_updatesafellamacontexthandle-llamakvcacheview" class="md-nav__link">
    llama_kv_cache_view_update(SafeLLamaContextHandle, LLamaKvCacheView&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_update(SafeLLamaContextHandle, LLamaKvCacheView&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_63" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_kv_cache_token_countsafellamacontexthandle" class="md-nav__link">
    llama_get_kv_cache_token_count(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_kv_cache_token_count(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_64" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_36" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_kv_cache_used_cellssafellamacontexthandle" class="md-nav__link">
    llama_get_kv_cache_used_cells(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_kv_cache_used_cells(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_65" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_37" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_beam_searchsafellamacontexthandle-llamabeamsearchcallback-intptr-uint64-int32-int32-int32" class="md-nav__link">
    llama_beam_search(SafeLLamaContextHandle, LLamaBeamSearchCallback, IntPtr, UInt64, Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_beam_search(SafeLLamaContextHandle, LLamaBeamSearchCallback, IntPtr, UInt64, Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_66" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_empty_call" class="md-nav__link">
    llama_empty_call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_max_devices" class="md-nav__link">
    llama_max_devices()
  </a>
  
    <nav class="md-nav" aria-label="llama_max_devices()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_38" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_default_params" class="md-nav__link">
    llama_model_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_model_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_39" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_context_default_params" class="md-nav__link">
    llama_context_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_context_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_40" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantize_default_params" class="md-nav__link">
    llama_model_quantize_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_41" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mmap" class="md-nav__link">
    llama_supports_mmap()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mmap()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_42" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mlock" class="md-nav__link">
    llama_supports_mlock()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mlock()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_43" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_gpu_offload" class="md-nav__link">
    llama_supports_gpu_offload()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_gpu_offload()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_44" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_rng_seedsafellamacontexthandle-uint32" class="md-nav__link">
    llama_set_rng_seed(SafeLLamaContextHandle, UInt32)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_rng_seed(SafeLLamaContextHandle, UInt32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_67" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_state_sizesafellamacontexthandle" class="md-nav__link">
    llama_get_state_size(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_state_size(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_68" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_45" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_copy_state_datasafellamacontexthandle-byte" class="md-nav__link">
    llama_copy_state_data(SafeLLamaContextHandle, Byte*)
  </a>
  
    <nav class="md-nav" aria-label="llama_copy_state_data(SafeLLamaContextHandle, Byte*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_69" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_46" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_state_datasafellamacontexthandle-byte" class="md-nav__link">
    llama_set_state_data(SafeLLamaContextHandle, Byte*)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_state_data(SafeLLamaContextHandle, Byte*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_70" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_47" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_load_session_filesafellamacontexthandle-string-llamatoken-uint64-uint64" class="md-nav__link">
    llama_load_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_load_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_71" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_48" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_save_session_filesafellamacontexthandle-string-llamatoken-uint64" class="md-nav__link">
    llama_save_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_save_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_72" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_49" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_textsafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_text(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_text(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_73" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_50" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_scoresafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_score(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_score(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_74" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_51" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_typesafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_type(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_type(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_75" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_52" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_ctxsafellamacontexthandle" class="md-nav__link">
    llama_n_ctx(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_ctx(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_76" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_53" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_batchsafellamacontexthandle" class="md-nav__link">
    llama_n_batch(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_batch(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_77" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_54" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_logitssafellamacontexthandle" class="md-nav__link">
    llama_get_logits(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_logits(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_78" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_55" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_logits_ithsafellamacontexthandle-int32" class="md-nav__link">
    llama_get_logits_ith(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_logits_ith(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_79" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_56" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddings_ithsafellamacontexthandle-int32" class="md-nav__link">
    llama_get_embeddings_ith(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings_ith(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_80" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_57" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.nativelibraryconfig/" class="md-nav__link">
        llama.native.nativelibraryconfig
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.ropescalingtype/" class="md-nav__link">
        llama.native.ropescalingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamacontexthandle/" class="md-nav__link">
        llama.native.safellamacontexthandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamagrammarhandle/" class="md-nav__link">
        llama.native.safellamagrammarhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamahandlebase/" class="md-nav__link">
        llama.native.safellamahandlebase
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamamodelhandle/" class="md-nav__link">
        llama.native.safellamamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellavaimageembedhandle/" class="md-nav__link">
        llama.native.safellavaimageembedhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellavamodelhandle/" class="md-nav__link">
        llama.native.safellavamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.quantizer/" class="md-nav__link">
        llama.quantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.basesamplingpipeline/" class="md-nav__link">
        llama.sampling.basesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.defaultsamplingpipeline/" class="md-nav__link">
        llama.sampling.defaultsamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.greedysamplingpipeline/" class="md-nav__link">
        llama.sampling.greedysamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.isamplingpipeline/" class="md-nav__link">
        llama.sampling.isamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.isamplingpipelineextensions/" class="md-nav__link">
        llama.sampling.isamplingpipelineextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.mirostate2samplingpipeline/" class="md-nav__link">
        llama.sampling.mirostate2samplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.mirostatesamplingpipeline/" class="md-nav__link">
        llama.sampling.mirostatesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sessionstate/" class="md-nav__link">
        llama.sessionstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.streamingtokendecoder/" class="md-nav__link">
        llama.streamingtokendecoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletion/" class="md-nav__link">
        llama.types.chatcompletion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchoice/" class="md-nav__link">
        llama.types.chatcompletionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunk/" class="md-nav__link">
        llama.types.chatcompletionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunkchoice/" class="md-nav__link">
        llama.types.chatcompletionchunkchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunkdelta/" class="md-nav__link">
        llama.types.chatcompletionchunkdelta
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionmessage/" class="md-nav__link">
        llama.types.chatcompletionmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatmessagerecord/" class="md-nav__link">
        llama.types.chatmessagerecord
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatrole/" class="md-nav__link">
        llama.types.chatrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completion/" class="md-nav__link">
        llama.types.completion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionchoice/" class="md-nav__link">
        llama.types.completionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionchunk/" class="md-nav__link">
        llama.types.completionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionlogprobs/" class="md-nav__link">
        llama.types.completionlogprobs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionusage/" class="md-nav__link">
        llama.types.completionusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embedding/" class="md-nav__link">
        llama.types.embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embeddingdata/" class="md-nav__link">
        llama.types.embeddingdata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embeddingusage/" class="md-nav__link">
        llama.types.embeddingusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../logger/" class="md-nav__link">
        logger
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_mirostatsafellamacontexthandle-llamatokendataarraynative-single-single-int32-single" class="md-nav__link">
    llama_sample_token_mirostat(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Int32, Single&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_mirostat(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Int32, Single&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_mirostat_v2safellamacontexthandle-llamatokendataarraynative-single-single-single" class="md-nav__link">
    llama_sample_token_mirostat_v2(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_mirostat_v2(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Single&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_token_greedysafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_token_greedy(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token_greedy(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tokensafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_token(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_token(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingsg__llama_get_embeddings_native30_0safellamacontexthandle" class="md-nav__link">
    &lt;llama_get_embeddings&gt;g__llama_get_embeddings_native|30_0(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="<llama_get_embeddings>g__llama_get_embeddings_native|30_0(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_pieceg__llama_token_to_piece_native44_0safellamamodelhandle-llamatoken-byte-int32" class="md-nav__link">
    &lt;llama_token_to_piece&gt;g__llama_token_to_piece_native|44_0(SafeLlamaModelHandle, LLamaToken, Byte*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="<llama_token_to_piece>g__llama_token_to_piece_native|44_0(SafeLlamaModelHandle, LLamaToken, Byte*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tryloadlibrariesg__tryload84_0string" class="md-nav__link">
    &lt;TryLoadLibraries&gt;g__TryLoad|84_0(String)
  </a>
  
    <nav class="md-nav" aria-label="<TryLoadLibraries>g__TryLoad|84_0(String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tryloadlibrariesg__tryfindpath84_1string-c__displayclass84_0" class="md-nav__link">
    &lt;TryLoadLibraries&gt;g__TryFindPath|84_1(String, &lt;&gt;c__DisplayClass84_0&amp;)
  </a>
  
    <nav class="md-nav" aria-label="<TryLoadLibraries>g__TryFindPath|84_1(String, <>c__DisplayClass84_0&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_n_threadssafellamacontexthandle-uint32-uint32" class="md-nav__link">
    llama_set_n_threads(SafeLLamaContextHandle, UInt32, UInt32)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_n_threads(SafeLLamaContextHandle, UInt32, UInt32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_vocab_typesafellamamodelhandle" class="md-nav__link">
    llama_vocab_type(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_vocab_type(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_rope_typesafellamamodelhandle" class="md-nav__link">
    llama_rope_type(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_rope_type(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_initllamagrammarelement-uint64-uint64" class="md-nav__link">
    llama_grammar_init(LLamaGrammarElement, UInt64, UInt64)**
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_init(LLamaGrammarElement, UInt64, UInt64)**">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_freeintptr" class="md-nav__link">
    llama_grammar_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_copysafellamagrammarhandle" class="md-nav__link">
    llama_grammar_copy(SafeLLamaGrammarHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_copy(SafeLLamaGrammarHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_grammarsafellamacontexthandle-llamatokendataarraynative-safellamagrammarhandle" class="md-nav__link">
    llama_sample_grammar(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, SafeLLamaGrammarHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_grammar(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, SafeLLamaGrammarHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_grammar_accept_tokensafellamacontexthandle-safellamagrammarhandle-llamatoken" class="md-nav__link">
    llama_grammar_accept_token(SafeLLamaContextHandle, SafeLLamaGrammarHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_grammar_accept_token(SafeLLamaContextHandle, SafeLLamaGrammarHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" class="md-nav__link">
    llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" class="md-nav__link">
    llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" class="md-nav__link">
    llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_freeintptr" class="md-nav__link">
    llava_image_embed_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" class="md-nav__link">
    llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantizestring-string-llamamodelquantizeparams" class="md-nav__link">
    llama_model_quantize(String, String, LLamaModelQuantizeParams*)
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize(String, String, LLamaModelQuantizeParams*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_repetition_penaltiessafellamacontexthandle-llamatokendataarraynative-llamatoken-uint64-single-single-single" class="md-nav__link">
    llama_sample_repetition_penalties(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, LLamaToken*, UInt64, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_repetition_penalties(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, LLamaToken*, UInt64, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_apply_guidancesafellamacontexthandle-spansingle-readonlyspansingle-single" class="md-nav__link">
    llama_sample_apply_guidance(SafeLLamaContextHandle, Span&lt;Single&gt;, ReadOnlySpan&lt;Single&gt;, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_apply_guidance(SafeLLamaContextHandle, Span<Single>, ReadOnlySpan<Single>, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_apply_guidancesafellamacontexthandle-single-single-single" class="md-nav__link">
    llama_sample_apply_guidance(SafeLLamaContextHandle, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_apply_guidance(SafeLLamaContextHandle, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_softmaxsafellamacontexthandle-llamatokendataarraynative" class="md-nav__link">
    llama_sample_softmax(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_softmax(SafeLLamaContextHandle, LLamaTokenDataArrayNative&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_top_ksafellamacontexthandle-llamatokendataarraynative-int32-uint64" class="md-nav__link">
    llama_sample_top_k(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Int32, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_top_k(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Int32, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_top_psafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_top_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_top_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_min_psafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_min_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_min_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tail_freesafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_tail_free(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_tail_free(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-uint64" class="md-nav__link">
    llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_30" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-single-single" class="md-nav__link">
    llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single, Single, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_31" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_sample_tempsafellamacontexthandle-llamatokendataarraynative-single" class="md-nav__link">
    llama_sample_temp(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single)
  </a>
  
    <nav class="md-nav" aria-label="llama_sample_temp(SafeLLamaContextHandle, LLamaTokenDataArrayNative&, Single)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_32" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingssafellamacontexthandle" class="md-nav__link">
    llama_get_embeddings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_33" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_apply_templatesafellamamodelhandle-char-llamachatmessage-intptr-boolean-char-int32" class="md-nav__link">
    llama_chat_apply_template(SafeLlamaModelHandle, Char, LLamaChatMessage, IntPtr, Boolean, Char*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_apply_template(SafeLlamaModelHandle, Char, LLamaChatMessage, IntPtr, Boolean, Char*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_34" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_bossafellamamodelhandle" class="md-nav__link">
    llama_token_bos(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_bos(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_35" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_eossafellamamodelhandle" class="md-nav__link">
    llama_token_eos(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_eos(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_36" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_nlsafellamamodelhandle" class="md-nav__link">
    llama_token_nl(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_nl(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_37" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_add_bos_tokensafellamamodelhandle" class="md-nav__link">
    llama_add_bos_token(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_add_bos_token(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_38" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_add_eos_tokensafellamamodelhandle" class="md-nav__link">
    llama_add_eos_token(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_add_eos_token(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_39" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_prefixsafellamamodelhandle" class="md-nav__link">
    llama_token_prefix(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_prefix(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_40" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_middlesafellamamodelhandle" class="md-nav__link">
    llama_token_middle(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_middle(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_41" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_suffixsafellamamodelhandle" class="md-nav__link">
    llama_token_suffix(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_suffix(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_42" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_eotsafellamamodelhandle" class="md-nav__link">
    llama_token_eot(SafeLlamaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_eot(SafeLlamaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_43" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_timingssafellamacontexthandle" class="md-nav__link">
    llama_print_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_print_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_44" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_reset_timingssafellamacontexthandle" class="md-nav__link">
    llama_reset_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_reset_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_45" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_system_info" class="md-nav__link">
    llama_print_system_info()
  </a>
  
    <nav class="md-nav" aria-label="llama_print_system_info()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_piecesafellamamodelhandle-llamatoken-spanbyte" class="md-nav__link">
    llama_token_to_piece(SafeLlamaModelHandle, LLamaToken, Span&lt;Byte&gt;)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_to_piece(SafeLlamaModelHandle, LLamaToken, Span<Byte>)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_46" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_tokenizesafellamamodelhandle-byte-int32-llamatoken-int32-boolean-boolean" class="md-nav__link">
    llama_tokenize(SafeLlamaModelHandle, Byte, Int32, LLamaToken, Int32, Boolean, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_tokenize(SafeLlamaModelHandle, Byte, Int32, LLamaToken, Int32, Boolean, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_47" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_30" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_log_setllamalogcallback" class="md-nav__link">
    llama_log_set(LLamaLogCallback)
  </a>
  
    <nav class="md-nav" aria-label="llama_log_set(LLamaLogCallback)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_48" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_clearsafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_clear(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_clear(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_49" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_cache_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_50" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_cpsafellamacontexthandle-llamaseqid-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_cache_seq_cp(SafeLLamaContextHandle, LLamaSeqId, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_cp(SafeLLamaContextHandle, LLamaSeqId, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_51" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_keepsafellamacontexthandle-llamaseqid" class="md-nav__link">
    llama_kv_cache_seq_keep(SafeLLamaContextHandle, LLamaSeqId)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_keep(SafeLLamaContextHandle, LLamaSeqId)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_52" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_addsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" class="md-nav__link">
    llama_kv_cache_seq_add(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_add(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_53" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_divsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" class="md-nav__link">
    llama_kv_cache_seq_div(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_div(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_54" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_seq_pos_maxsafellamacontexthandle-llamaseqid" class="md-nav__link">
    llama_kv_cache_seq_pos_max(SafeLLamaContextHandle, LLamaSeqId)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_seq_pos_max(SafeLLamaContextHandle, LLamaSeqId)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_55" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_31" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_defragsafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_defrag(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_defrag(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_56" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_32" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_updatesafellamacontexthandle" class="md-nav__link">
    llama_kv_cache_update(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_update(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_57" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_initint32-int32-int32" class="md-nav__link">
    llama_batch_init(Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_init(Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_58" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_33" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_freellamanativebatch" class="md-nav__link">
    llama_batch_free(LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_free(LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_59" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_decodesafellamacontexthandle-llamanativebatch" class="md-nav__link">
    llama_decode(SafeLLamaContextHandle, LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_decode(SafeLLamaContextHandle, LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_60" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_34" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_initsafellamacontexthandle-int32" class="md-nav__link">
    llama_kv_cache_view_init(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_init(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_61" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_35" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_freellamakvcacheview" class="md-nav__link">
    llama_kv_cache_view_free(LLamaKvCacheView&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_free(LLamaKvCacheView&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_62" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_cache_view_updatesafellamacontexthandle-llamakvcacheview" class="md-nav__link">
    llama_kv_cache_view_update(SafeLLamaContextHandle, LLamaKvCacheView&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_cache_view_update(SafeLLamaContextHandle, LLamaKvCacheView&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_63" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_kv_cache_token_countsafellamacontexthandle" class="md-nav__link">
    llama_get_kv_cache_token_count(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_kv_cache_token_count(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_64" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_36" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_kv_cache_used_cellssafellamacontexthandle" class="md-nav__link">
    llama_get_kv_cache_used_cells(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_kv_cache_used_cells(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_65" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_37" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_beam_searchsafellamacontexthandle-llamabeamsearchcallback-intptr-uint64-int32-int32-int32" class="md-nav__link">
    llama_beam_search(SafeLLamaContextHandle, LLamaBeamSearchCallback, IntPtr, UInt64, Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_beam_search(SafeLLamaContextHandle, LLamaBeamSearchCallback, IntPtr, UInt64, Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_66" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_empty_call" class="md-nav__link">
    llama_empty_call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_max_devices" class="md-nav__link">
    llama_max_devices()
  </a>
  
    <nav class="md-nav" aria-label="llama_max_devices()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_38" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_default_params" class="md-nav__link">
    llama_model_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_model_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_39" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_context_default_params" class="md-nav__link">
    llama_context_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_context_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_40" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantize_default_params" class="md-nav__link">
    llama_model_quantize_default_params()
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize_default_params()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_41" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mmap" class="md-nav__link">
    llama_supports_mmap()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mmap()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_42" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mlock" class="md-nav__link">
    llama_supports_mlock()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mlock()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_43" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_gpu_offload" class="md-nav__link">
    llama_supports_gpu_offload()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_gpu_offload()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_44" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_rng_seedsafellamacontexthandle-uint32" class="md-nav__link">
    llama_set_rng_seed(SafeLLamaContextHandle, UInt32)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_rng_seed(SafeLLamaContextHandle, UInt32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_67" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_state_sizesafellamacontexthandle" class="md-nav__link">
    llama_get_state_size(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_state_size(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_68" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_45" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_copy_state_datasafellamacontexthandle-byte" class="md-nav__link">
    llama_copy_state_data(SafeLLamaContextHandle, Byte*)
  </a>
  
    <nav class="md-nav" aria-label="llama_copy_state_data(SafeLLamaContextHandle, Byte*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_69" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_46" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_state_datasafellamacontexthandle-byte" class="md-nav__link">
    llama_set_state_data(SafeLLamaContextHandle, Byte*)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_state_data(SafeLLamaContextHandle, Byte*)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_70" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_47" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_load_session_filesafellamacontexthandle-string-llamatoken-uint64-uint64" class="md-nav__link">
    llama_load_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_load_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_71" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_48" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_save_session_filesafellamacontexthandle-string-llamatoken-uint64" class="md-nav__link">
    llama_save_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_save_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_72" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_49" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_textsafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_text(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_text(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_73" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_50" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_scoresafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_score(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_score(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_74" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_51" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_get_typesafellamamodelhandle-llamatoken" class="md-nav__link">
    llama_token_get_type(SafeLlamaModelHandle, LLamaToken)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_get_type(SafeLlamaModelHandle, LLamaToken)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_75" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_52" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_ctxsafellamacontexthandle" class="md-nav__link">
    llama_n_ctx(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_ctx(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_76" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_53" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_batchsafellamacontexthandle" class="md-nav__link">
    llama_n_batch(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_batch(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_77" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_54" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_logitssafellamacontexthandle" class="md-nav__link">
    llama_get_logits(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_logits(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_78" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_55" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_logits_ithsafellamacontexthandle-int32" class="md-nav__link">
    llama_get_logits_ith(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_logits_ith(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_79" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_56" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddings_ithsafellamacontexthandle-int32" class="md-nav__link">
    llama_get_embeddings_ith(SafeLLamaContextHandle, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings_ith(SafeLLamaContextHandle, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_80" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_57" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="nativeapi">NativeApi<a class="headerlink" href="#nativeapi" title="Permanent link"></a></h1>
<p>Namespace: LLama.Native</p>
<p>Direct translation of the llama.cpp API</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">NativeApi</span>
</code></pre></div></td></tr></table></div>
<p>Inheritance <a href="https://docs.microsoft.com/en-us/dotnet/api/system.object">Object</a>  <a href="./">NativeApi</a></p>
<h2 id="methods">Methods<a class="headerlink" href="#methods" title="Permanent link"></a></h2>
<h3 id="llama_sample_token_mirostatsafellamacontexthandle-llamatokendataarraynative-single-single-int32-single"><strong>llama_sample_token_mirostat(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Int32, Single&amp;)</strong><a class="headerlink" href="#llama_sample_token_mirostatsafellamacontexthandle-llamatokendataarraynative-single-single-int32-single" title="Permanent link"></a></h3>
<p>Mirostat 1.0 algorithm described in the paper <a href="https://arxiv.org/abs/2007.14966">https://arxiv.org/abs/2007.14966</a>. Uses tokens instead of words.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_sample_token_mirostat</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tau</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">eta</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">Single</span><span class="o">&amp;</span><span class="w"> </span><span class="n">mu</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
A vector of <code>llama_token_data</code> containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.</p>
<p><code>tau</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.</p>
<p><code>eta</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
The learning rate used to update <code>mu</code> based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause <code>mu</code> to be updated more quickly, while a smaller learning rate will result in slower updates.</p>
<p><code>m</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The number of tokens considered in the estimation of <code>s_hat</code>. This is an arbitrary value that is used to calculate <code>s_hat</code>, which in turn helps to calculate the value of <code>k</code>. In the paper, they use <code>m = 100</code>, but you can experiment with different values to see how it affects the performance of the algorithm.</p>
<p><code>mu</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single&amp;">Single&amp;</a><br>
Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (<code>2 * tau</code>) and is updated in the algorithm based on the error between the target and observed surprisal.</p>
<h4 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_sample_token_mirostat_v2safellamacontexthandle-llamatokendataarraynative-single-single-single"><strong>llama_sample_token_mirostat_v2(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single&amp;)</strong><a class="headerlink" href="#llama_sample_token_mirostat_v2safellamacontexthandle-llamatokendataarraynative-single-single-single" title="Permanent link"></a></h3>
<p>Mirostat 2.0 algorithm described in the paper <a href="https://arxiv.org/abs/2007.14966">https://arxiv.org/abs/2007.14966</a>. Uses tokens instead of words.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_sample_token_mirostat_v2</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tau</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">eta</span><span class="p">,</span><span class="w"> </span><span class="n">Single</span><span class="o">&amp;</span><span class="w"> </span><span class="n">mu</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
A vector of <code>llama_token_data</code> containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.</p>
<p><code>tau</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.</p>
<p><code>eta</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
The learning rate used to update <code>mu</code> based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause <code>mu</code> to be updated more quickly, while a smaller learning rate will result in slower updates.</p>
<p><code>mu</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single&amp;">Single&amp;</a><br>
Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (<code>2 * tau</code>) and is updated in the algorithm based on the error between the target and observed surprisal.</p>
<h4 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_sample_token_greedysafellamacontexthandle-llamatokendataarraynative"><strong>llama_sample_token_greedy(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)</strong><a class="headerlink" href="#llama_sample_token_greedysafellamacontexthandle-llamatokendataarraynative" title="Permanent link"></a></h3>
<p>Selects the token with the highest probability.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_sample_token_greedy</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<h4 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_sample_tokensafellamacontexthandle-llamatokendataarraynative"><strong>llama_sample_token(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)</strong><a class="headerlink" href="#llama_sample_tokensafellamacontexthandle-llamatokendataarraynative" title="Permanent link"></a></h3>
<p>Randomly selects a token from the candidates based on their probabilities.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_sample_token</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<h4 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_get_embeddingsg__llama_get_embeddings_native30_0safellamacontexthandle"><strong>&lt;llama_get_embeddings&gt;g__llama_get_embeddings_native|30_0(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_embeddingsg__llama_get_embeddings_native30_0safellamacontexthandle" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">internal</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="o">&lt;</span><span class="n">llama_get_embeddings</span><span class="o">&gt;</span><span class="n">g__llama_get_embeddings_native</span><span class="o">|</span><span class="m">30</span><span class="n">_0</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>
<h3 id="llama_token_to_pieceg__llama_token_to_piece_native44_0safellamamodelhandle-llamatoken-byte-int32"><strong>&lt;llama_token_to_piece&gt;g__llama_token_to_piece_native|44_0(SafeLlamaModelHandle, LLamaToken, Byte*, Int32)</strong><a class="headerlink" href="#llama_token_to_pieceg__llama_token_to_piece_native44_0safellamamodelhandle-llamatoken-byte-int32" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">internal</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">&lt;</span><span class="n">llama_token_to_piece</span><span class="o">&gt;</span><span class="n">g__llama_token_to_piece_native</span><span class="o">|</span><span class="m">44</span><span class="n">_0</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">llamaToken</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">length</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>llamaToken</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<p><code>buffer</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br></p>
<p><code>length</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="tryloadlibrariesg__tryload84_0string"><strong>&lt;TryLoadLibraries&gt;g__TryLoad|84_0(String)</strong><a class="headerlink" href="#tryloadlibrariesg__tryload84_0string" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">internal</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="o">&lt;</span><span class="n">TryLoadLibraries</span><span class="o">&gt;</span><span class="n">g__TryLoad</span><span class="o">|</span><span class="m">84</span><span class="n">_0</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link"></a></h4>
<p><code>path</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<h4 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="tryloadlibrariesg__tryfindpath84_1string-c__displayclass84_0"><strong>&lt;TryLoadLibraries&gt;g__TryFindPath|84_1(String, &lt;&gt;c__DisplayClass84_0&amp;)</strong><a class="headerlink" href="#tryloadlibrariesg__tryfindpath84_1string-c__displayclass84_0" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">internal</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="o">&lt;</span><span class="n">TryLoadLibraries</span><span class="o">&gt;</span><span class="n">g__TryFindPath</span><span class="o">|</span><span class="m">84</span><span class="n">_1</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">filename</span><span class="p">,</span><span class="w"> </span><span class="o">&lt;&gt;</span><span class="n">c__DisplayClass84_0</span><span class="o">&amp;</span><span class="w"> </span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link"></a></h4>
<p><code>filename</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p>`` <a href="./llama.native.nativeapi.&lt;&gt;c__displayclass84_0&amp;.md">&lt;&gt;c__DisplayClass84_0&amp;</a><br></p>
<h4 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<h3 id="llama_set_n_threadssafellamacontexthandle-uint32-uint32"><strong>llama_set_n_threads(SafeLLamaContextHandle, UInt32, UInt32)</strong><a class="headerlink" href="#llama_set_n_threadssafellamacontexthandle-uint32-uint32" title="Permanent link"></a></h3>
<p>Set the number of threads used for decoding</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_set_n_threads</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="n">n_threads</span><span class="p">,</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="n">n_threads_batch</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br>
n_threads is the number of threads used for generation (single token)</p>
<p><code>n_threads_batch</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br>
n_threads_batch is the number of threads used for prompt and batch processing (multiple tokens)</p>
<h3 id="llama_vocab_typesafellamamodelhandle"><strong>llama_vocab_type(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_vocab_typesafellamamodelhandle" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaVocabType</span><span class="w"> </span><span class="nf">llama_vocab_type</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamavocabtype/">LLamaVocabType</a><br></p>
<h3 id="llama_rope_typesafellamamodelhandle"><strong>llama_rope_type(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_rope_typesafellamamodelhandle" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaRopeType</span><span class="w"> </span><span class="nf">llama_rope_type</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamaropetype/">LLamaRopeType</a><br></p>
<h3 id="llama_grammar_initllamagrammarelement-uint64-uint64"><strong>llama_grammar_init(LLamaGrammarElement</strong>, UInt64, UInt64)**<a class="headerlink" href="#llama_grammar_initllamagrammarelement-uint64-uint64" title="Permanent link"></a></h3>
<p>Create a new grammar from the given set of grammar rules</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">llama_grammar_init</span><span class="p">(</span><span class="n">LLamaGrammarElement</span><span class="o">**</span><span class="w"> </span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_rules</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">start_rule_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link"></a></h4>
<p><code>rules</code> <a href="./llama.native.llamagrammarelement**.md">LLamaGrammarElement**</a><br></p>
<p><code>n_rules</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<p><code>start_rule_index</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h4 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_grammar_freeintptr"><strong>llama_grammar_free(IntPtr)</strong><a class="headerlink" href="#llama_grammar_freeintptr" title="Permanent link"></a></h3>
<p>Free all memory from the given SafeLLamaGrammarHandle</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_grammar_free</span><span class="p">(</span><span class="n">IntPtr</span><span class="w"> </span><span class="n">grammar</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link"></a></h4>
<p><code>grammar</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_grammar_copysafellamagrammarhandle"><strong>llama_grammar_copy(SafeLLamaGrammarHandle)</strong><a class="headerlink" href="#llama_grammar_copysafellamagrammarhandle" title="Permanent link"></a></h3>
<p>Create a copy of an existing grammar instance</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">llama_grammar_copy</span><span class="p">(</span><span class="n">SafeLLamaGrammarHandle</span><span class="w"> </span><span class="n">grammar</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link"></a></h4>
<p><code>grammar</code> <a href="../llama.native.safellamagrammarhandle/">SafeLLamaGrammarHandle</a><br></p>
<h4 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_sample_grammarsafellamacontexthandle-llamatokendataarraynative-safellamagrammarhandle"><strong>llama_sample_grammar(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, SafeLLamaGrammarHandle)</strong><a class="headerlink" href="#llama_sample_grammarsafellamacontexthandle-llamatokendataarraynative-safellamagrammarhandle" title="Permanent link"></a></h3>
<p>Apply constraints from grammar</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_grammar</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLLamaGrammarHandle</span><span class="w"> </span><span class="n">grammar</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br></p>
<p><code>grammar</code> <a href="../llama.native.safellamagrammarhandle/">SafeLLamaGrammarHandle</a><br></p>
<h3 id="llama_grammar_accept_tokensafellamacontexthandle-safellamagrammarhandle-llamatoken"><strong>llama_grammar_accept_token(SafeLLamaContextHandle, SafeLLamaGrammarHandle, LLamaToken)</strong><a class="headerlink" href="#llama_grammar_accept_tokensafellamacontexthandle-safellamagrammarhandle-llamatoken" title="Permanent link"></a></h3>
<p>Accepts the sampled token into the grammar</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_grammar_accept_token</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLLamaGrammarHandle</span><span class="w"> </span><span class="n">grammar</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">token</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>grammar</code> <a href="../llama.native.safellamagrammarhandle/">SafeLLamaGrammarHandle</a><br></p>
<p><code>token</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle"><strong>llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)</strong><a class="headerlink" href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" title="Permanent link"></a></h3>
<p>Sanity check for clip &lt;-&gt; llava embed size match</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llava_validate_embed_size</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctxLlama</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctxClip</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link"></a></h4>
<p><code>ctxLlama</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br>
LLama Context</p>
<p><code>ctxClip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
Llava Model</p>
<h4 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
True if validate successfully</p>
<h3 id="llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32"><strong>llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)</strong><a class="headerlink" href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" title="Permanent link"></a></h3>
<p>Build an image embed from image file bytes</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="nf">llava_image_embed_make_with_bytes</span><span class="p">(</span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctx_clip</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_threads</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="p">[]</span><span class="w"> </span><span class="n">image_bytes</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">image_bytes_length</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link"></a></h4>
<p><code>ctx_clip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
SafeHandle to the Clip Model</p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of threads</p>
<p><code>image_bytes</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte">Byte[]</a><br>
Binary image in jpeg format</p>
<p><code>image_bytes_length</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Bytes lenght of the image</p>
<h4 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link"></a></h4>
<p><a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
SafeHandle to the Embeddings</p>
<h3 id="llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string"><strong>llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)</strong><a class="headerlink" href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" title="Permanent link"></a></h3>
<p>Build an image embed from a path to an image filename</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="nf">llava_image_embed_make_with_filename</span><span class="p">(</span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctx_clip</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_threads</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">image_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link"></a></h4>
<p><code>ctx_clip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
SafeHandle to the Clip Model</p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of threads</p>
<p><code>image_path</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br>
Image filename (jpeg) to generate embeddings</p>
<h4 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link"></a></h4>
<p><a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
SafeHandel to the embeddings</p>
<h3 id="llava_image_embed_freeintptr"><strong>llava_image_embed_free(IntPtr)</strong><a class="headerlink" href="#llava_image_embed_freeintptr" title="Permanent link"></a></h3>
<p>Free an embedding made with llava_image_embed_make_*</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llava_image_embed_free</span><span class="p">(</span><span class="n">IntPtr</span><span class="w"> </span><span class="n">embed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link"></a></h4>
<p><code>embed</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Embeddings to release</p>
<h3 id="llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32"><strong>llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)</strong><a class="headerlink" href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" title="Permanent link"></a></h3>
<p>Write the image represented by embed into the llama context with batch size n_batch, starting at context
 pos n_past. on completion, n_past points to the next position in the context after the image embed.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llava_eval_image_embed</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx_llama</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="n">embed</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_batch</span><span class="p">,</span><span class="w"> </span><span class="n">Int32</span><span class="o">&amp;</span><span class="w"> </span><span class="n">n_past</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link"></a></h4>
<p><code>ctx_llama</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br>
Llama Context</p>
<p><code>embed</code> <a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
Embedding handle</p>
<p><code>n_batch</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>n_past</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32&amp;">Int32&amp;</a><br></p>
<h4 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
True on success</p>
<h3 id="llama_model_quantizestring-string-llamamodelquantizeparams"><strong>llama_model_quantize(String, String, LLamaModelQuantizeParams*)</strong><a class="headerlink" href="#llama_model_quantizestring-string-llamamodelquantizeparams" title="Permanent link"></a></h3>
<p>Returns 0 on success</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="nf">llama_model_quantize</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">fname_inp</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">fname_out</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaModelQuantizeParams</span><span class="o">*</span><span class="w"> </span><span class="n">param</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link"></a></h4>
<p><code>fname_inp</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>fname_out</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>param</code> <a href="./llama.native.llamamodelquantizeparams*.md">LLamaModelQuantizeParams*</a><br></p>
<h4 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br>
Returns 0 on success</p>
<h3 id="llama_sample_repetition_penaltiessafellamacontexthandle-llamatokendataarraynative-llamatoken-uint64-single-single-single"><strong>llama_sample_repetition_penalties(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, LLamaToken*, UInt64, Single, Single, Single)</strong><a class="headerlink" href="#llama_sample_repetition_penaltiessafellamacontexthandle-llamatokendataarraynative-llamatoken-uint64-single-single-single" title="Permanent link"></a></h3>
<p>Repetition penalty described in CTRL academic paper <a href="https://arxiv.org/abs/1909.05858">https://arxiv.org/abs/1909.05858</a>, with negative logit fix.
 Frequency and presence penalties described in OpenAI API <a href="https://platform.openai.com/docs/api-reference/parameter-details">https://platform.openai.com/docs/api-reference/parameter-details</a>.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_repetition_penalties</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="o">*</span><span class="w"> </span><span class="n">last_tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">last_tokens_size</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">penalty_repeat</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">penalty_freq</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">penalty_present</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>last_tokens</code> <a href="./llama.native.llamatoken*.md">LLamaToken*</a><br></p>
<p><code>last_tokens_size</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<p><code>penalty_repeat</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
Repetition penalty described in CTRL academic paper <a href="https://arxiv.org/abs/1909.05858">https://arxiv.org/abs/1909.05858</a>, with negative logit fix.</p>
<p><code>penalty_freq</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
Frequency and presence penalties described in OpenAI API <a href="https://platform.openai.com/docs/api-reference/parameter-details">https://platform.openai.com/docs/api-reference/parameter-details</a>.</p>
<p><code>penalty_present</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
Frequency and presence penalties described in OpenAI API <a href="https://platform.openai.com/docs/api-reference/parameter-details">https://platform.openai.com/docs/api-reference/parameter-details</a>.</p>
<h3 id="llama_sample_apply_guidancesafellamacontexthandle-spansingle-readonlyspansingle-single"><strong>llama_sample_apply_guidance(SafeLLamaContextHandle, Span&lt;Single&gt;, ReadOnlySpan&lt;Single&gt;, Single)</strong><a class="headerlink" href="#llama_sample_apply_guidancesafellamacontexthandle-spansingle-readonlyspansingle-single" title="Permanent link"></a></h3>
<p>Apply classifier-free guidance to the logits as described in academic paper "Stay on topic with Classifier-Free Guidance" <a href="https://arxiv.org/abs/2306.17806">https://arxiv.org/abs/2306.17806</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_apply_guidance</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">Span</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">logits</span><span class="p">,</span><span class="w"> </span><span class="n">ReadOnlySpan</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">logits_guidance</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>logits</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.span-1">Span&lt;Single&gt;</a><br>
Logits extracted from the original generation context.</p>
<p><code>logits_guidance</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.readonlyspan-1">ReadOnlySpan&lt;Single&gt;</a><br>
Logits extracted from a separate context from the same model.
 Other than a negative prompt at the beginning, it should have all generated and user input tokens copied from the main context.</p>
<p><code>scale</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
Guidance strength. 1.0f means no guidance. Higher values mean stronger guidance.</p>
<h3 id="llama_sample_apply_guidancesafellamacontexthandle-single-single-single"><strong>llama_sample_apply_guidance(SafeLLamaContextHandle, Single<em>, Single</em>, Single)</strong><a class="headerlink" href="#llama_sample_apply_guidancesafellamacontexthandle-single-single-single" title="Permanent link"></a></h3>
<p>Apply classifier-free guidance to the logits as described in academic paper "Stay on topic with Classifier-Free Guidance" <a href="https://arxiv.org/abs/2306.17806">https://arxiv.org/abs/2306.17806</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_apply_guidance</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">logits</span><span class="p">,</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">logits_guidance</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>logits</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br>
Logits extracted from the original generation context.</p>
<p><code>logits_guidance</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br>
Logits extracted from a separate context from the same model.
 Other than a negative prompt at the beginning, it should have all generated and user input tokens copied from the main context.</p>
<p><code>scale</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br>
Guidance strength. 1.0f means no guidance. Higher values mean stronger guidance.</p>
<h3 id="llama_sample_softmaxsafellamacontexthandle-llamatokendataarraynative"><strong>llama_sample_softmax(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;)</strong><a class="headerlink" href="#llama_sample_softmaxsafellamacontexthandle-llamatokendataarraynative" title="Permanent link"></a></h3>
<p>Sorts candidate tokens by their logits in descending order and calculate probabilities based on logits.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_softmax</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<h3 id="llama_sample_top_ksafellamacontexthandle-llamatokendataarraynative-int32-uint64"><strong>llama_sample_top_k(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Int32, UInt64)</strong><a class="headerlink" href="#llama_sample_top_ksafellamacontexthandle-llamatokendataarraynative-int32-uint64" title="Permanent link"></a></h3>
<p>Top-K sampling described in academic paper "The Curious Case of Neural Text Degeneration" <a href="https://arxiv.org/abs/1904.09751">https://arxiv.org/abs/1904.09751</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_top_k</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">min_keep</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>k</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>min_keep</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_sample_top_psafellamacontexthandle-llamatokendataarraynative-single-uint64"><strong>llama_sample_top_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)</strong><a class="headerlink" href="#llama_sample_top_psafellamacontexthandle-llamatokendataarraynative-single-uint64" title="Permanent link"></a></h3>
<p>Nucleus sampling described in academic paper "The Curious Case of Neural Text Degeneration" <a href="https://arxiv.org/abs/1904.09751">https://arxiv.org/abs/1904.09751</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_top_p</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">min_keep</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>p</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>min_keep</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_sample_min_psafellamacontexthandle-llamatokendataarraynative-single-uint64"><strong>llama_sample_min_p(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)</strong><a class="headerlink" href="#llama_sample_min_psafellamacontexthandle-llamatokendataarraynative-single-uint64" title="Permanent link"></a></h3>
<p>Minimum P sampling as described in <a href="https://github.com/ggerganov/llama.cpp/pull/3841">https://github.com/ggerganov/llama.cpp/pull/3841</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_min_p</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">min_keep</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>p</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>min_keep</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_sample_tail_freesafellamacontexthandle-llamatokendataarraynative-single-uint64"><strong>llama_sample_tail_free(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)</strong><a class="headerlink" href="#llama_sample_tail_freesafellamacontexthandle-llamatokendataarraynative-single-uint64" title="Permanent link"></a></h3>
<p>Tail Free Sampling described in <a href="https://www.trentonbricken.com/Tail-Free-Sampling/">https://www.trentonbricken.com/Tail-Free-Sampling/</a>.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_tail_free</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">min_keep</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>z</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>min_keep</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-uint64"><strong>llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, UInt64)</strong><a class="headerlink" href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-uint64" title="Permanent link"></a></h3>
<p>Locally Typical Sampling implementation described in the paper <a href="https://arxiv.org/abs/2202.00666">https://arxiv.org/abs/2202.00666</a>.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_typical</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">min_keep</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_30">Parameters<a class="headerlink" href="#parameters_30" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>p</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>min_keep</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-single-single"><strong>llama_sample_typical(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single, Single, Single)</strong><a class="headerlink" href="#llama_sample_typicalsafellamacontexthandle-llamatokendataarraynative-single-single-single" title="Permanent link"></a></h3>
<p>Dynamic temperature implementation described in the paper <a href="https://arxiv.org/abs/2309.02772">https://arxiv.org/abs/2309.02772</a>.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_typical</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">min_temp</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">max_temp</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">exponent_val</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_31">Parameters<a class="headerlink" href="#parameters_31" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br>
Pointer to LLamaTokenDataArray</p>
<p><code>min_temp</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>max_temp</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<p><code>exponent_val</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<h3 id="llama_sample_tempsafellamacontexthandle-llamatokendataarraynative-single"><strong>llama_sample_temp(SafeLLamaContextHandle, LLamaTokenDataArrayNative&amp;, Single)</strong><a class="headerlink" href="#llama_sample_tempsafellamacontexthandle-llamatokendataarraynative-single" title="Permanent link"></a></h3>
<p>Modify logits by temperature</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_sample_temp</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaTokenDataArrayNative</span><span class="o">&amp;</span><span class="w"> </span><span class="n">candidates</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">temp</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_32">Parameters<a class="headerlink" href="#parameters_32" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>candidates</code> <a href="./llama.native.llamatokendataarraynative&amp;.md">LLamaTokenDataArrayNative&amp;</a><br></p>
<p><code>temp</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<h3 id="llama_get_embeddingssafellamacontexthandle"><strong>llama_get_embeddings(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_embeddingssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Get the embeddings for the input</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Span</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">llama_get_embeddings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_33">Parameters<a class="headerlink" href="#parameters_33" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.span-1">Span&lt;Single&gt;</a><br></p>
<h3 id="llama_chat_apply_templatesafellamamodelhandle-char-llamachatmessage-intptr-boolean-char-int32"><strong>llama_chat_apply_template(SafeLlamaModelHandle, Char<em>, LLamaChatMessage</em>, IntPtr, Boolean, Char*, Int32)</strong><a class="headerlink" href="#llama_chat_apply_templatesafellamamodelhandle-char-llamachatmessage-intptr-boolean-char-int32" title="Permanent link"></a></h3>
<p>Apply chat template. Inspired by hf apply_chat_template() on python.
 Both "model" and "custom_template" are optional, but at least one is required. "custom_template" has higher precedence than "model"
 NOTE: This function does not use a jinja parser. It only support a pre-defined list of template. See more: <a href="https://github.com/ggerganov/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template">https://github.com/ggerganov/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_chat_apply_template</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Char</span><span class="o">*</span><span class="w"> </span><span class="n">tmpl</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaChatMessage</span><span class="o">*</span><span class="w"> </span><span class="n">chat</span><span class="p">,</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="n">n_msg</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">add_ass</span><span class="p">,</span><span class="w"> </span><span class="n">Char</span><span class="o">*</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">length</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_34">Parameters<a class="headerlink" href="#parameters_34" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>tmpl</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.char*">Char*</a><br>
A Jinja template to use for this chat. If this is nullptr, the models default chat template will be used instead.</p>
<p><code>chat</code> <a href="./llama.native.llamachatmessage*.md">LLamaChatMessage*</a><br>
Pointer to a list of multiple llama_chat_message</p>
<p><code>n_msg</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Number of llama_chat_message in this chat</p>
<p><code>add_ass</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
Whether to end the prompt with the token(s) that indicate the start of an assistant message.</p>
<p><code>buf</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.char*">Char*</a><br>
A buffer to hold the output formatted prompt. The recommended alloc size is 2 * (total number of characters of all messages)</p>
<p><code>length</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The size of the allocated buffer</p>
<h4 id="returns_18">Returns<a class="headerlink" href="#returns_18" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The total number of bytes of the formatted prompt. If is it larger than the size of buffer, you may need to re-alloc it and then re-apply the template.</p>
<h3 id="llama_token_bossafellamamodelhandle"><strong>llama_token_bos(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_bossafellamamodelhandle" title="Permanent link"></a></h3>
<p>Get the "Beginning of sentence" token</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_token_bos</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_35">Parameters<a class="headerlink" href="#parameters_35" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_19">Returns<a class="headerlink" href="#returns_19" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_token_eossafellamamodelhandle"><strong>llama_token_eos(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_eossafellamamodelhandle" title="Permanent link"></a></h3>
<p>Get the "End of sentence" token</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_token_eos</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_36">Parameters<a class="headerlink" href="#parameters_36" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_20">Returns<a class="headerlink" href="#returns_20" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_token_nlsafellamamodelhandle"><strong>llama_token_nl(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_nlsafellamamodelhandle" title="Permanent link"></a></h3>
<p>Get the "new line" token</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="nf">llama_token_nl</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_37">Parameters<a class="headerlink" href="#parameters_37" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_21">Returns<a class="headerlink" href="#returns_21" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h3 id="llama_add_bos_tokensafellamamodelhandle"><strong>llama_add_bos_token(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_add_bos_tokensafellamamodelhandle" title="Permanent link"></a></h3>
<p>Returns -1 if unknown, 1 for true or 0 for false.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_add_bos_token</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_38">Parameters<a class="headerlink" href="#parameters_38" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_22">Returns<a class="headerlink" href="#returns_22" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_add_eos_tokensafellamamodelhandle"><strong>llama_add_eos_token(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_add_eos_tokensafellamamodelhandle" title="Permanent link"></a></h3>
<p>Returns -1 if unknown, 1 for true or 0 for false.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_add_eos_token</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_39">Parameters<a class="headerlink" href="#parameters_39" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_23">Returns<a class="headerlink" href="#returns_23" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_token_prefixsafellamamodelhandle"><strong>llama_token_prefix(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_prefixsafellamamodelhandle" title="Permanent link"></a></h3>
<p>codellama infill tokens, Beginning of infill prefix</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_prefix</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_40">Parameters<a class="headerlink" href="#parameters_40" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_24">Returns<a class="headerlink" href="#returns_24" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_token_middlesafellamamodelhandle"><strong>llama_token_middle(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_middlesafellamamodelhandle" title="Permanent link"></a></h3>
<p>codellama infill tokens, Beginning of infill middle</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_middle</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_41">Parameters<a class="headerlink" href="#parameters_41" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_25">Returns<a class="headerlink" href="#returns_25" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_token_suffixsafellamamodelhandle"><strong>llama_token_suffix(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_suffixsafellamamodelhandle" title="Permanent link"></a></h3>
<p>codellama infill tokens, Beginning of infill suffix</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_suffix</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_42">Parameters<a class="headerlink" href="#parameters_42" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_26">Returns<a class="headerlink" href="#returns_26" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_token_eotsafellamamodelhandle"><strong>llama_token_eot(SafeLlamaModelHandle)</strong><a class="headerlink" href="#llama_token_eotsafellamamodelhandle" title="Permanent link"></a></h3>
<p>codellama infill tokens, End of infill middle</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_eot</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_43">Parameters<a class="headerlink" href="#parameters_43" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<h4 id="returns_27">Returns<a class="headerlink" href="#returns_27" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_print_timingssafellamacontexthandle"><strong>llama_print_timings(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_print_timingssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Print out timing information for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_print_timings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_44">Parameters<a class="headerlink" href="#parameters_44" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h3 id="llama_reset_timingssafellamacontexthandle"><strong>llama_reset_timings(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_reset_timingssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Reset all collected timing information for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_reset_timings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_45">Parameters<a class="headerlink" href="#parameters_45" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h3 id="llama_print_system_info"><strong>llama_print_system_info()</strong><a class="headerlink" href="#llama_print_system_info" title="Permanent link"></a></h3>
<p>Print system information</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">llama_print_system_info</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_28">Returns<a class="headerlink" href="#returns_28" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_token_to_piecesafellamamodelhandle-llamatoken-spanbyte"><strong>llama_token_to_piece(SafeLlamaModelHandle, LLamaToken, Span&lt;Byte&gt;)</strong><a class="headerlink" href="#llama_token_to_piecesafellamamodelhandle-llamatoken-spanbyte" title="Permanent link"></a></h3>
<p>Convert a single token into text</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_to_piece</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">llamaToken</span><span class="p">,</span><span class="w"> </span><span class="n">Span</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">&gt;</span><span class="w"> </span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_46">Parameters<a class="headerlink" href="#parameters_46" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>llamaToken</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<p><code>buffer</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.span-1">Span&lt;Byte&gt;</a><br>
buffer to write string into</p>
<h4 id="returns_29">Returns<a class="headerlink" href="#returns_29" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The length written, or if the buffer is too small a negative that indicates the length required</p>
<h3 id="llama_tokenizesafellamamodelhandle-byte-int32-llamatoken-int32-boolean-boolean"><strong>llama_tokenize(SafeLlamaModelHandle, Byte<em>, Int32, LLamaToken</em>, Int32, Boolean, Boolean)</strong><a class="headerlink" href="#llama_tokenizesafellamamodelhandle-byte-int32-llamatoken-int32-boolean-boolean" title="Permanent link"></a></h3>
<p>Convert text into tokens</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_tokenize</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">text</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">text_len</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="o">*</span><span class="w"> </span><span class="n">tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_max_tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">add_bos</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">special</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_47">Parameters<a class="headerlink" href="#parameters_47" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>text</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br></p>
<p><code>text_len</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>tokens</code> <a href="./llama.native.llamatoken*.md">LLamaToken*</a><br></p>
<p><code>n_max_tokens</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>add_bos</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<p><code>special</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
Allow tokenizing special and/or control tokens which otherwise are not exposed and treated as plaintext. Does not insert a leading space.</p>
<h4 id="returns_30">Returns<a class="headerlink" href="#returns_30" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Returns the number of tokens on success, no more than n_max_tokens.
 Returns a negative number on failure - the number of tokens that would have been returned</p>
<h3 id="llama_log_setllamalogcallback"><strong>llama_log_set(LLamaLogCallback)</strong><a class="headerlink" href="#llama_log_setllamalogcallback" title="Permanent link"></a></h3>
<p>Register a callback to receive llama log messages</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_log_set</span><span class="p">(</span><span class="n">LLamaLogCallback</span><span class="w"> </span><span class="n">logCallback</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_48">Parameters<a class="headerlink" href="#parameters_48" title="Permanent link"></a></h4>
<p><code>logCallback</code> <a href="./llama.native.llamalogcallback.md">LLamaLogCallback</a><br></p>
<h3 id="llama_kv_cache_clearsafellamacontexthandle"><strong>llama_kv_cache_clear(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_kv_cache_clearsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Clear the KV cache</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_clear</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_49">Parameters<a class="headerlink" href="#parameters_49" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h3 id="llama_kv_cache_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos"><strong>llama_kv_cache_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)</strong><a class="headerlink" href="#llama_kv_cache_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" title="Permanent link"></a></h3>
<p>Removes all tokens that belong to the specified sequence and have positions in [p0, p1)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_rm</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_50">Parameters<a class="headerlink" href="#parameters_50" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>p0</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>p1</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<h3 id="llama_kv_cache_seq_cpsafellamacontexthandle-llamaseqid-llamaseqid-llamapos-llamapos"><strong>llama_kv_cache_seq_cp(SafeLLamaContextHandle, LLamaSeqId, LLamaSeqId, LLamaPos, LLamaPos)</strong><a class="headerlink" href="#llama_kv_cache_seq_cpsafellamacontexthandle-llamaseqid-llamaseqid-llamapos-llamapos" title="Permanent link"></a></h3>
<p>Copy all tokens that belong to the specified sequence to another sequence
 Note that this does not allocate extra KV cache memory - it simply assigns the tokens to the new sequence</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_cp</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">dest</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_51">Parameters<a class="headerlink" href="#parameters_51" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>src</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>dest</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>p0</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>p1</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<h3 id="llama_kv_cache_seq_keepsafellamacontexthandle-llamaseqid"><strong>llama_kv_cache_seq_keep(SafeLLamaContextHandle, LLamaSeqId)</strong><a class="headerlink" href="#llama_kv_cache_seq_keepsafellamacontexthandle-llamaseqid" title="Permanent link"></a></h3>
<p>Removes all tokens that do not belong to the specified sequence</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_keep</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_52">Parameters<a class="headerlink" href="#parameters_52" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<h3 id="llama_kv_cache_seq_addsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32"><strong>llama_kv_cache_seq_add(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)</strong><a class="headerlink" href="#llama_kv_cache_seq_addsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" title="Permanent link"></a></h3>
<p>Adds relative position "delta" to all tokens that belong to the specified sequence and have positions in [p0, p1)
 If the KV cache is RoPEd, the KV data is updated accordingly:
 - lazily on next llama_decode()
 - explicitly with llama_kv_cache_update()</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_add</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p1</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">delta</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_53">Parameters<a class="headerlink" href="#parameters_53" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>p0</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>p1</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>delta</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_kv_cache_seq_divsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32"><strong>llama_kv_cache_seq_div(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos, Int32)</strong><a class="headerlink" href="#llama_kv_cache_seq_divsafellamacontexthandle-llamaseqid-llamapos-llamapos-int32" title="Permanent link"></a></h3>
<p>Integer division of the positions by factor of <code>d &amp;gt; 1</code>
 If the KV cache is RoPEd, the KV data is updated accordingly:
 - lazily on next llama_decode()
 - explicitly with llama_kv_cache_update()
 <br>
 p0 &lt; 0 : [0, p1]
 <br>
 p1 &lt; 0 : [p0, inf)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_div</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p1</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">d</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_54">Parameters<a class="headerlink" href="#parameters_54" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>p0</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>p1</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>d</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_kv_cache_seq_pos_maxsafellamacontexthandle-llamaseqid"><strong>llama_kv_cache_seq_pos_max(SafeLLamaContextHandle, LLamaSeqId)</strong><a class="headerlink" href="#llama_kv_cache_seq_pos_maxsafellamacontexthandle-llamaseqid" title="Permanent link"></a></h3>
<p>Returns the largest position present in the KV cache for the specified sequence</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="nf">llama_kv_cache_seq_pos_max</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_55">Parameters<a class="headerlink" href="#parameters_55" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<h4 id="returns_31">Returns<a class="headerlink" href="#returns_31" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<h3 id="llama_kv_cache_defragsafellamacontexthandle"><strong>llama_kv_cache_defrag(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_kv_cache_defragsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Defragment the KV cache. This will be applied:
 - lazily on next llama_decode()
 - explicitly with llama_kv_cache_update()</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="nf">llama_kv_cache_defrag</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_56">Parameters<a class="headerlink" href="#parameters_56" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_32">Returns<a class="headerlink" href="#returns_32" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<h3 id="llama_kv_cache_updatesafellamacontexthandle"><strong>llama_kv_cache_update(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_kv_cache_updatesafellamacontexthandle" title="Permanent link"></a></h3>
<p>Apply the KV cache updates (such as K-shifts, defragmentation, etc.)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_update</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_57">Parameters<a class="headerlink" href="#parameters_57" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h3 id="llama_batch_initint32-int32-int32"><strong>llama_batch_init(Int32, Int32, Int32)</strong><a class="headerlink" href="#llama_batch_initint32-int32-int32" title="Permanent link"></a></h3>
<p>Allocates a batch of tokens on the heap
 Each token can be assigned up to n_seq_max sequence ids
 The batch has to be freed with llama_batch_free()
 If embd != 0, llama_batch.embd will be allocated with size of n_tokens * embd * sizeof(float)
 Otherwise, llama_batch.token will be allocated to store n_tokens llama_token
 The rest of the llama_batch members are allocated with size n_tokens
 All members are left uninitialized</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaNativeBatch</span><span class="w"> </span><span class="nf">llama_batch_init</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n_tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">embd</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_seq_max</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_58">Parameters<a class="headerlink" href="#parameters_58" title="Permanent link"></a></h4>
<p><code>n_tokens</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>embd</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>n_seq_max</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Each token can be assigned up to n_seq_max sequence ids</p>
<h4 id="returns_33">Returns<a class="headerlink" href="#returns_33" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamanativebatch/">LLamaNativeBatch</a><br></p>
<h3 id="llama_batch_freellamanativebatch"><strong>llama_batch_free(LLamaNativeBatch)</strong><a class="headerlink" href="#llama_batch_freellamanativebatch" title="Permanent link"></a></h3>
<p>Frees a batch of tokens allocated with llama_batch_init()</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_batch_free</span><span class="p">(</span><span class="n">LLamaNativeBatch</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_59">Parameters<a class="headerlink" href="#parameters_59" title="Permanent link"></a></h4>
<p><code>batch</code> <a href="../llama.native.llamanativebatch/">LLamaNativeBatch</a><br></p>
<h3 id="llama_decodesafellamacontexthandle-llamanativebatch"><strong>llama_decode(SafeLLamaContextHandle, LLamaNativeBatch)</strong><a class="headerlink" href="#llama_decodesafellamacontexthandle-llamanativebatch" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_decode</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaNativeBatch</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_60">Parameters<a class="headerlink" href="#parameters_60" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>batch</code> <a href="../llama.native.llamanativebatch/">LLamaNativeBatch</a><br></p>
<h4 id="returns_34">Returns<a class="headerlink" href="#returns_34" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Positive return values does not mean a fatal error, but rather a warning:<br>
 - 0: success<br>
 - 1: could not find a KV slot for the batch (try reducing the size of the batch or increase the context)<br>
 - &lt; 0: error<br></p>
<h3 id="llama_kv_cache_view_initsafellamacontexthandle-int32"><strong>llama_kv_cache_view_init(SafeLLamaContextHandle, Int32)</strong><a class="headerlink" href="#llama_kv_cache_view_initsafellamacontexthandle-int32" title="Permanent link"></a></h3>
<p>Create an empty KV cache view. (use only for debugging purposes)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaKvCacheView</span><span class="w"> </span><span class="nf">llama_kv_cache_view_init</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_max_seq</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_61">Parameters<a class="headerlink" href="#parameters_61" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>n_max_seq</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_35">Returns<a class="headerlink" href="#returns_35" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamakvcacheview/">LLamaKvCacheView</a><br></p>
<h3 id="llama_kv_cache_view_freellamakvcacheview"><strong>llama_kv_cache_view_free(LLamaKvCacheView&amp;)</strong><a class="headerlink" href="#llama_kv_cache_view_freellamakvcacheview" title="Permanent link"></a></h3>
<p>Free a KV cache view. (use only for debugging purposes)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_view_free</span><span class="p">(</span><span class="n">LLamaKvCacheView</span><span class="o">&amp;</span><span class="w"> </span><span class="n">view</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_62">Parameters<a class="headerlink" href="#parameters_62" title="Permanent link"></a></h4>
<p><code>view</code> <a href="./llama.native.llamakvcacheview&amp;.md">LLamaKvCacheView&amp;</a><br></p>
<h3 id="llama_kv_cache_view_updatesafellamacontexthandle-llamakvcacheview"><strong>llama_kv_cache_view_update(SafeLLamaContextHandle, LLamaKvCacheView&amp;)</strong><a class="headerlink" href="#llama_kv_cache_view_updatesafellamacontexthandle-llamakvcacheview" title="Permanent link"></a></h3>
<p>Update the KV cache view structure with the current state of the KV cache. (use only for debugging purposes)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_kv_cache_view_update</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaKvCacheView</span><span class="o">&amp;</span><span class="w"> </span><span class="n">view</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_63">Parameters<a class="headerlink" href="#parameters_63" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>view</code> <a href="./llama.native.llamakvcacheview&amp;.md">LLamaKvCacheView&amp;</a><br></p>
<h3 id="llama_get_kv_cache_token_countsafellamacontexthandle"><strong>llama_get_kv_cache_token_count(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_kv_cache_token_countsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Returns the number of tokens in the KV cache (slow, use only for debug)
 If a KV cell has multiple sequences assigned to it, it will be counted multiple times</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_get_kv_cache_token_count</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_64">Parameters<a class="headerlink" href="#parameters_64" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_36">Returns<a class="headerlink" href="#returns_36" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_get_kv_cache_used_cellssafellamacontexthandle"><strong>llama_get_kv_cache_used_cells(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_kv_cache_used_cellssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Returns the number of used KV cells (i.e. have at least one sequence assigned to them)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_get_kv_cache_used_cells</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_65">Parameters<a class="headerlink" href="#parameters_65" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_37">Returns<a class="headerlink" href="#returns_37" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_beam_searchsafellamacontexthandle-llamabeamsearchcallback-intptr-uint64-int32-int32-int32"><strong>llama_beam_search(SafeLLamaContextHandle, LLamaBeamSearchCallback, IntPtr, UInt64, Int32, Int32, Int32)</strong><a class="headerlink" href="#llama_beam_searchsafellamacontexthandle-llamabeamsearchcallback-intptr-uint64-int32-int32-int32" title="Permanent link"></a></h3>
<p>Deterministically returns entire sentence constructed by a beam search.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_beam_search</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaBeamSearchCallback</span><span class="w"> </span><span class="n">callback</span><span class="p">,</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="n">callback_data</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_beams</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_past</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_predict</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_threads</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_66">Parameters<a class="headerlink" href="#parameters_66" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br>
Pointer to the llama_context.</p>
<p><code>callback</code> <a href="./llama.native.nativeapi.llamabeamsearchcallback.md">LLamaBeamSearchCallback</a><br>
Invoked for each iteration of the beam_search loop, passing in beams_state.</p>
<p><code>callback_data</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
A pointer that is simply passed back to callback.</p>
<p><code>n_beams</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br>
Number of beams to use.</p>
<p><code>n_past</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of tokens already evaluated.</p>
<p><code>n_predict</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Maximum number of tokens to predict. EOS may occur earlier.</p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of threads.</p>
<h3 id="llama_empty_call"><strong>llama_empty_call()</strong><a class="headerlink" href="#llama_empty_call" title="Permanent link"></a></h3>
<p>A method that does nothing. This is a native method, calling it will force the llama native dependencies to be loaded.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_empty_call</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h3 id="llama_max_devices"><strong>llama_max_devices()</strong><a class="headerlink" href="#llama_max_devices" title="Permanent link"></a></h3>
<p>Get the maximum number of devices supported by llama.cpp</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="nf">llama_max_devices</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_38">Returns<a class="headerlink" href="#returns_38" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int64">Int64</a><br></p>
<h3 id="llama_model_default_params"><strong>llama_model_default_params()</strong><a class="headerlink" href="#llama_model_default_params" title="Permanent link"></a></h3>
<p>Create a LLamaModelParams with default values</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaModelParams</span><span class="w"> </span><span class="nf">llama_model_default_params</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_39">Returns<a class="headerlink" href="#returns_39" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamamodelparams/">LLamaModelParams</a><br></p>
<h3 id="llama_context_default_params"><strong>llama_context_default_params()</strong><a class="headerlink" href="#llama_context_default_params" title="Permanent link"></a></h3>
<p>Create a LLamaContextParams with default values</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaContextParams</span><span class="w"> </span><span class="nf">llama_context_default_params</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_40">Returns<a class="headerlink" href="#returns_40" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamacontextparams/">LLamaContextParams</a><br></p>
<h3 id="llama_model_quantize_default_params"><strong>llama_model_quantize_default_params()</strong><a class="headerlink" href="#llama_model_quantize_default_params" title="Permanent link"></a></h3>
<p>Create a LLamaModelQuantizeParams with default values</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaModelQuantizeParams</span><span class="w"> </span><span class="nf">llama_model_quantize_default_params</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_41">Returns<a class="headerlink" href="#returns_41" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamamodelquantizeparams/">LLamaModelQuantizeParams</a><br></p>
<h3 id="llama_supports_mmap"><strong>llama_supports_mmap()</strong><a class="headerlink" href="#llama_supports_mmap" title="Permanent link"></a></h3>
<p>Check if memory mapping is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_mmap</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_42">Returns<a class="headerlink" href="#returns_42" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_supports_mlock"><strong>llama_supports_mlock()</strong><a class="headerlink" href="#llama_supports_mlock" title="Permanent link"></a></h3>
<p>Check if memory locking is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_mlock</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_43">Returns<a class="headerlink" href="#returns_43" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_supports_gpu_offload"><strong>llama_supports_gpu_offload()</strong><a class="headerlink" href="#llama_supports_gpu_offload" title="Permanent link"></a></h3>
<p>Check if GPU offload is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_gpu_offload</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_44">Returns<a class="headerlink" href="#returns_44" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_set_rng_seedsafellamacontexthandle-uint32"><strong>llama_set_rng_seed(SafeLLamaContextHandle, UInt32)</strong><a class="headerlink" href="#llama_set_rng_seedsafellamacontexthandle-uint32" title="Permanent link"></a></h3>
<p>Sets the current rng seed.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_set_rng_seed</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_67">Parameters<a class="headerlink" href="#parameters_67" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seed</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br></p>
<h3 id="llama_get_state_sizesafellamacontexthandle"><strong>llama_get_state_size(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_state_sizesafellamacontexthandle" title="Permanent link"></a></h3>
<p>Returns the maximum size in bytes of the state (rng, logits, embedding
 and kv_cache) - will often be smaller after compacting tokens</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="nf">llama_get_state_size</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_68">Parameters<a class="headerlink" href="#parameters_68" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_45">Returns<a class="headerlink" href="#returns_45" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h3 id="llama_copy_state_datasafellamacontexthandle-byte"><strong>llama_copy_state_data(SafeLLamaContextHandle, Byte*)</strong><a class="headerlink" href="#llama_copy_state_datasafellamacontexthandle-byte" title="Permanent link"></a></h3>
<p>Copies the state to the specified destination address.
 Destination needs to have allocated enough memory.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="nf">llama_copy_state_data</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">dest</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_69">Parameters<a class="headerlink" href="#parameters_69" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>dest</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br></p>
<h4 id="returns_46">Returns<a class="headerlink" href="#returns_46" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br>
the number of bytes copied</p>
<h3 id="llama_set_state_datasafellamacontexthandle-byte"><strong>llama_set_state_data(SafeLLamaContextHandle, Byte*)</strong><a class="headerlink" href="#llama_set_state_datasafellamacontexthandle-byte" title="Permanent link"></a></h3>
<p>Set the state reading from the specified address</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="nf">llama_set_state_data</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_70">Parameters<a class="headerlink" href="#parameters_70" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>src</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br></p>
<h4 id="returns_47">Returns<a class="headerlink" href="#returns_47" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br>
the number of bytes read</p>
<h3 id="llama_load_session_filesafellamacontexthandle-string-llamatoken-uint64-uint64"><strong>llama_load_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)</strong><a class="headerlink" href="#llama_load_session_filesafellamacontexthandle-string-llamatoken-uint64-uint64" title="Permanent link"></a></h3>
<p>Load session file</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_load_session_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">path_session</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="p">[]</span><span class="w"> </span><span class="n">tokens_out</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_token_capacity</span><span class="p">,</span><span class="w"> </span><span class="n">UInt64</span><span class="o">&amp;</span><span class="w"> </span><span class="n">n_token_count_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_71">Parameters<a class="headerlink" href="#parameters_71" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>path_session</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>tokens_out</code> <a href="../llama.native.llamatoken/">LLamaToken[]</a><br></p>
<p><code>n_token_capacity</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<p><code>n_token_count_out</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64&amp;">UInt64&amp;</a><br></p>
<h4 id="returns_48">Returns<a class="headerlink" href="#returns_48" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_save_session_filesafellamacontexthandle-string-llamatoken-uint64"><strong>llama_save_session_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)</strong><a class="headerlink" href="#llama_save_session_filesafellamacontexthandle-string-llamatoken-uint64" title="Permanent link"></a></h3>
<p>Save session file</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_save_session_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">path_session</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="p">[]</span><span class="w"> </span><span class="n">tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_token_count</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_72">Parameters<a class="headerlink" href="#parameters_72" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>path_session</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>tokens</code> <a href="../llama.native.llamatoken/">LLamaToken[]</a><br></p>
<p><code>n_token_count</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h4 id="returns_49">Returns<a class="headerlink" href="#returns_49" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_token_get_textsafellamamodelhandle-llamatoken"><strong>llama_token_get_text(SafeLlamaModelHandle, LLamaToken)</strong><a class="headerlink" href="#llama_token_get_textsafellamamodelhandle-llamatoken" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">llama_token_get_text</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">token</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_73">Parameters<a class="headerlink" href="#parameters_73" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>token</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h4 id="returns_50">Returns<a class="headerlink" href="#returns_50" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br></p>
<h3 id="llama_token_get_scoresafellamamodelhandle-llamatoken"><strong>llama_token_get_score(SafeLlamaModelHandle, LLamaToken)</strong><a class="headerlink" href="#llama_token_get_scoresafellamamodelhandle-llamatoken" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="nf">llama_token_get_score</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">token</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_74">Parameters<a class="headerlink" href="#parameters_74" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>token</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h4 id="returns_51">Returns<a class="headerlink" href="#returns_51" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single">Single</a><br></p>
<h3 id="llama_token_get_typesafellamamodelhandle-llamatoken"><strong>llama_token_get_type(SafeLlamaModelHandle, LLamaToken)</strong><a class="headerlink" href="#llama_token_get_typesafellamamodelhandle-llamatoken" title="Permanent link"></a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaTokenType</span><span class="w"> </span><span class="nf">llama_token_get_type</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">token</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_75">Parameters<a class="headerlink" href="#parameters_75" title="Permanent link"></a></h4>
<p><code>model</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>token</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<h4 id="returns_52">Returns<a class="headerlink" href="#returns_52" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamatokentype/">LLamaTokenType</a><br></p>
<h3 id="llama_n_ctxsafellamacontexthandle"><strong>llama_n_ctx(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_n_ctxsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Get the size of the context window for the model for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="nf">llama_n_ctx</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_76">Parameters<a class="headerlink" href="#parameters_76" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_53">Returns<a class="headerlink" href="#returns_53" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br></p>
<h3 id="llama_n_batchsafellamacontexthandle"><strong>llama_n_batch(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_n_batchsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Get the batch size for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="nf">llama_n_batch</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_77">Parameters<a class="headerlink" href="#parameters_77" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_54">Returns<a class="headerlink" href="#returns_54" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br></p>
<h3 id="llama_get_logitssafellamacontexthandle"><strong>llama_get_logits(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_logitssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Token logits obtained from the last call to llama_decode
 The logits for the last token are stored in the last row
 Can be mutated in order to change the probabilities of the next token.<br>
 Rows: n_tokens<br>
 Cols: n_vocab</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">llama_get_logits</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_78">Parameters<a class="headerlink" href="#parameters_78" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_55">Returns<a class="headerlink" href="#returns_55" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>
<h3 id="llama_get_logits_ithsafellamacontexthandle-int32"><strong>llama_get_logits_ith(SafeLLamaContextHandle, Int32)</strong><a class="headerlink" href="#llama_get_logits_ithsafellamacontexthandle-int32" title="Permanent link"></a></h3>
<p>Logits for the ith token. Equivalent to: llama_get_logits(ctx) + i*n_vocab</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">llama_get_logits_ith</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_79">Parameters<a class="headerlink" href="#parameters_79" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>i</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_56">Returns<a class="headerlink" href="#returns_56" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>
<h3 id="llama_get_embeddings_ithsafellamacontexthandle-int32"><strong>llama_get_embeddings_ith(SafeLLamaContextHandle, Int32)</strong><a class="headerlink" href="#llama_get_embeddings_ithsafellamacontexthandle-int32" title="Permanent link"></a></h3>
<p>Get the embeddings for the ith sequence. Equivalent to: llama_get_embeddings(ctx) + i*n_embd</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">llama_get_embeddings_ith</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_80">Parameters<a class="headerlink" href="#parameters_80" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>i</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_57">Returns<a class="headerlink" href="#returns_57" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "navigation.instant"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>