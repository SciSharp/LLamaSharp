
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../llama.native.llavaimageembed/">
      
      
        <link rel="next" href="../llama.native.nativelibraryconfig/">
      
      <link rel="icon" href="../../media/icon128.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.20">
    
    
      
        <title>llama.native.nativeapi - LLamaSharp Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,700,700i%7CFira+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Fira Sans";--md-code-font:"Fira Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css?v=14">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#nativeapi" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="LLamaSharp Documentation" class="md-header__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 9h5.5L13 3.5V9M6 2h8l6 6v12a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4c0-1.11.89-2 2-2m9 16v-2H6v2h9m3-4v-2H6v2h12Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLamaSharp Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              llama.native.nativeapi
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="LLamaSharp Documentation" class="md-nav__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 9h5.5L13 3.5V9M6 2h8l6 6v12a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4c0-1.11.89-2 2-2m9 16v-2H6v2h9m3-4v-2H6v2h12Z"/></svg>

    </a>
    LLamaSharp Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../QuickStart/" class="md-nav__link">
        Quick Start
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../Architecture/" class="md-nav__link">
        Architecture
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../FAQ/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../ContributingGuide/" class="md-nav__link">
        Contributing Guide
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/NativeLibraryConfig/" class="md-nav__link">
        Configure the native library loading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/Executors/" class="md-nav__link">
        Use executors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/ChatSession/" class="md-nav__link">
        Use ChatSession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/UnderstandLLamaContext/" class="md-nav__link">
        Understand LLamaContext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Tutorials/Quantization/" class="md-nav__link">
        Quantize the model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          Advanced Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Advanced Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../AdvancedTutorials/CustomizeNativeLibraryLoading/" class="md-nav__link">
        Customize the native library loading
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          Integrations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Integrations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/semantic-kernel/" class="md-nav__link">
        semantic-kernel integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/kernel-memory/" class="md-nav__link">
        kernel-memory integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/BotSharp.md" class="md-nav__link">
        BotSharp integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Integrations/Langchain.md" class="md-nav__link">
        Langchain integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
      
      
      
        <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorFork/" class="md-nav__link">
        Bacthed executor - multi-output to one input
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorGuidance/" class="md-nav__link">
        Batched executor - basic guidance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/BatchedExecutorRewind/" class="md-nav__link">
        Batched executor - rewinding to an earlier state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatChineseGB2312/" class="md-nav__link">
        Chinese LLM - with GB2312 encoding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionStripRoleName/" class="md-nav__link">
        ChatSession - stripping role names
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithHistory/" class="md-nav__link">
        ChatSession - with history
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRestart/" class="md-nav__link">
        ChatSession - restarting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/ChatSessionWithRoleName/" class="md-nav__link">
        ChatSession - Basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/CodingAssistant/" class="md-nav__link">
        Coding assistant
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/GrammarJsonResponse/" class="md-nav__link">
        Grammar - json response
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InstructModeExecute/" class="md-nav__link">
        Instruct executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/InteractiveModeExecute/" class="md-nav__link">
        Interactive executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemory/" class="md-nav__link">
        Kernel memory integration - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/KernelMemorySaveAndLoad/" class="md-nav__link">
        Kernel-memory - save & load
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LLavaInteractiveModeExecute/" class="md-nav__link">
        LLaVA - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveSession/" class="md-nav__link">
        ChatSession - load & save
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/LoadAndSaveState/" class="md-nav__link">
        Executor - save/load state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/QuantizeModel/" class="md-nav__link">
        Quantization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelChat/" class="md-nav__link">
        Semantic-kernel - chat
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelMemory/" class="md-nav__link">
        Semantic-kernel - with kernel-memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/SemanticKernelPrompt/" class="md-nav__link">
        Semantic-kernel - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/StatelessModeExecute/" class="md-nav__link">
        Stateless executor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Examples/TalkToYourself/" class="md-nav__link">
        Talk to yourself
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" checked>
      
      
      
        <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.adaptercollection.md" class="md-nav__link">
        llama.abstractions.adaptercollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.icontextparams/" class="md-nav__link">
        llama.abstractions.icontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.ihistorytransform/" class="md-nav__link">
        llama.abstractions.ihistorytransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.iinferenceparams/" class="md-nav__link">
        llama.abstractions.iinferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.illamaexecutor/" class="md-nav__link">
        llama.abstractions.illamaexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.illamaparams/" class="md-nav__link">
        llama.abstractions.illamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.imodelparams/" class="md-nav__link">
        llama.abstractions.imodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.itextstreamtransform/" class="md-nav__link">
        llama.abstractions.itextstreamtransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.itexttransform/" class="md-nav__link">
        llama.abstractions.itexttransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.loraadapter.md" class="md-nav__link">
        llama.abstractions.loraadapter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.metadataoverride/" class="md-nav__link">
        llama.abstractions.metadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.metadataoverrideconverter/" class="md-nav__link">
        llama.abstractions.metadataoverrideconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.tensorsplitscollection/" class="md-nav__link">
        llama.abstractions.tensorsplitscollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.abstractions.tensorsplitscollectionconverter/" class="md-nav__link">
        llama.abstractions.tensorsplitscollectionconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.antipromptprocessor/" class="md-nav__link">
        llama.antipromptprocessor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.alreadypromptedconversationexception/" class="md-nav__link">
        llama.batched.alreadypromptedconversationexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.batchedexecutor/" class="md-nav__link">
        llama.batched.batchedexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotforkwhilerequiresinferenceexception.md" class="md-nav__link">
        llama.batched.cannotforkwhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotmodifywhilerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotmodifywhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotsamplerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotsamplerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.cannotsamplerequirespromptexception/" class="md-nav__link">
        llama.batched.cannotsamplerequirespromptexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.conversation/" class="md-nav__link">
        llama.batched.conversation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.conversationextensions/" class="md-nav__link">
        llama.batched.conversationextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.batched.experimentalbatchedexecutorexception/" class="md-nav__link">
        llama.batched.experimentalbatchedexecutorexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.chatsession-1.md" class="md-nav__link">
        llama.chatsession-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.chatsession/" class="md-nav__link">
        llama.chatsession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.authorrole/" class="md-nav__link">
        llama.common.authorrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.chathistory/" class="md-nav__link">
        llama.common.chathistory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.fixedsizequeue-1/" class="md-nav__link">
        llama.common.fixedsizequeue-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.inferenceparams/" class="md-nav__link">
        llama.common.inferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.mirostattype/" class="md-nav__link">
        llama.common.mirostattype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.common.modelparams/" class="md-nav__link">
        llama.common.modelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectedname.md" class="md-nav__link">
        llama.exceptions.grammarexpectedname
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectednext.md" class="md-nav__link">
        llama.exceptions.grammarexpectednext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarexpectedprevious.md" class="md-nav__link">
        llama.exceptions.grammarexpectedprevious
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarformatexception.md" class="md-nav__link">
        llama.exceptions.grammarformatexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedcharaltelement.md" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharaltelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedcharrngelement.md" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharrngelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedendelement.md" class="md-nav__link">
        llama.exceptions.grammarunexpectedendelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedendofinput.md" class="md-nav__link">
        llama.exceptions.grammarunexpectedendofinput
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunexpectedhexcharscount.md" class="md-nav__link">
        llama.exceptions.grammarunexpectedhexcharscount
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.grammarunknownescapecharacter.md" class="md-nav__link">
        llama.exceptions.grammarunknownescapecharacter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.llamadecodeerror/" class="md-nav__link">
        llama.exceptions.llamadecodeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.loadweightsfailedexception/" class="md-nav__link">
        llama.exceptions.loadweightsfailedexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.exceptions.runtimeerror/" class="md-nav__link">
        llama.exceptions.runtimeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.extensions.icontextparamsextensions/" class="md-nav__link">
        llama.extensions.icontextparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.extensions.imodelparamsextensions/" class="md-nav__link">
        llama.extensions.imodelparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.grammars.grammar.md" class="md-nav__link">
        llama.grammars.grammar
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.grammars.grammarrule.md" class="md-nav__link">
        llama.grammars.grammarrule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.ichatmodel.md" class="md-nav__link">
        llama.ichatmodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamacache.md" class="md-nav__link">
        llama.llamacache
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaembedder/" class="md-nav__link">
        llama.llamaembedder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamamodel.md" class="md-nav__link">
        llama.llamamodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamamodelv1.md" class="md-nav__link">
        llama.llamamodelv1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaparams.md" class="md-nav__link">
        llama.llamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamaquantizer/" class="md-nav__link">
        llama.llamaquantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamastate.md" class="md-nav__link">
        llama.llamastate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llamatransforms/" class="md-nav__link">
        llama.llamatransforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.llavaweights/" class="md-nav__link">
        llama.llavaweights
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.decoderesult/" class="md-nav__link">
        llama.native.decoderesult
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.ggmltype/" class="md-nav__link">
        llama.native.ggmltype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.gpusplitmode/" class="md-nav__link">
        llama.native.gpusplitmode
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabatch/" class="md-nav__link">
        llama.native.llamabatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabeamsstate.md" class="md-nav__link">
        llama.native.llamabeamsstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamabeamview.md" class="md-nav__link">
        llama.native.llamabeamview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamachatmessage/" class="md-nav__link">
        llama.native.llamachatmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamacontextparams/" class="md-nav__link">
        llama.native.llamacontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaftype/" class="md-nav__link">
        llama.native.llamaftype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamagrammarelement.md" class="md-nav__link">
        llama.native.llamagrammarelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamagrammarelementtype.md" class="md-nav__link">
        llama.native.llamagrammarelementtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheview.md" class="md-nav__link">
        llama.native.llamakvcacheview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheviewcell.md" class="md-nav__link">
        llama.native.llamakvcacheviewcell
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamakvcacheviewsafehandle/" class="md-nav__link">
        llama.native.llamakvcacheviewsafehandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaloglevel/" class="md-nav__link">
        llama.native.llamaloglevel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelkvoverridetype/" class="md-nav__link">
        llama.native.llamamodelkvoverridetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelmetadataoverride/" class="md-nav__link">
        llama.native.llamamodelmetadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelparams/" class="md-nav__link">
        llama.native.llamamodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamamodelquantizeparams/" class="md-nav__link">
        llama.native.llamamodelquantizeparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamanativebatch/" class="md-nav__link">
        llama.native.llamanativebatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamapoolingtype/" class="md-nav__link">
        llama.native.llamapoolingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamapos/" class="md-nav__link">
        llama.native.llamapos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaropetype/" class="md-nav__link">
        llama.native.llamaropetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamaseqid/" class="md-nav__link">
        llama.native.llamaseqid
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatoken/" class="md-nav__link">
        llama.native.llamatoken
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendata/" class="md-nav__link">
        llama.native.llamatokendata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendataarray/" class="md-nav__link">
        llama.native.llamatokendataarray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokendataarraynative/" class="md-nav__link">
        llama.native.llamatokendataarraynative
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamatokentype.md" class="md-nav__link">
        llama.native.llamatokentype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llamavocabtype/" class="md-nav__link">
        llama.native.llamavocabtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.llavaimageembed/" class="md-nav__link">
        llama.native.llavaimageembed
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          llama.native.nativeapi
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        llama.native.nativeapi
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama_empty_call" class="md-nav__link">
    llama_empty_call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_backend_free" class="md-nav__link">
    llama_backend_free()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_max_devices" class="md-nav__link">
    llama_max_devices()
  </a>
  
    <nav class="md-nav" aria-label="llama_max_devices()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mmap" class="md-nav__link">
    llama_supports_mmap()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mmap()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mlock" class="md-nav__link">
    llama_supports_mlock()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mlock()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_gpu_offload" class="md-nav__link">
    llama_supports_gpu_offload()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_gpu_offload()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_rpc" class="md-nav__link">
    llama_supports_rpc()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_rpc()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_load_filesafellamacontexthandle-string-llamatoken-uint64-uint64" class="md-nav__link">
    llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_save_filesafellamacontexthandle-string-llamatoken-uint64" class="md-nav__link">
    llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_seq_save_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr" class="md-nav__link">
    llama_state_seq_save_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_seq_save_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_seq_load_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr-uintptr" class="md-nav__link">
    llama_state_seq_load_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr, UIntPtr&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_seq_load_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr, UIntPtr&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_causal_attnsafellamacontexthandle-boolean" class="md-nav__link">
    llama_set_causal_attn(SafeLLamaContextHandle, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_causal_attn(SafeLLamaContextHandle, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_embeddingssafellamacontexthandle-boolean" class="md-nav__link">
    llama_set_embeddings(SafeLLamaContextHandle, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_embeddings(SafeLLamaContextHandle, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_abort_callbacksafellamamodelhandle-intptr-intptr" class="md-nav__link">
    llama_set_abort_callback(SafeLlamaModelHandle, IntPtr, IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_abort_callback(SafeLlamaModelHandle, IntPtr, IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_seq_maxsafellamacontexthandle" class="md-nav__link">
    llama_n_seq_max(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_seq_max(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingssafellamacontexthandle" class="md-nav__link">
    llama_get_embeddings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_apply_templatebyte-llamachatmessage-uintptr-boolean-byte-int32" class="md-nav__link">
    llama_chat_apply_template(Byte, LLamaChatMessage, UIntPtr, Boolean, Byte*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_apply_template(Byte, LLamaChatMessage, UIntPtr, Boolean, Byte*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_builtin_templateschar-uintptr" class="md-nav__link">
    llama_chat_builtin_templates(Char, UIntPtr)**
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_builtin_templates(Char, UIntPtr)**">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_timingssafellamacontexthandle" class="md-nav__link">
    llama_print_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_print_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_system_info" class="md-nav__link">
    llama_print_system_info()
  </a>
  
    <nav class="md-nav" aria-label="llama_print_system_info()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_piecevocabulary-llamatoken-spanbyte-int32-boolean" class="md-nav__link">
    llama_token_to_piece(Vocabulary, LLamaToken, Span&lt;Byte&gt;, Int32, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_to_piece(Vocabulary, LLamaToken, Span<Byte>, Int32, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_log_setllamalogcallback" class="md-nav__link">
    llama_log_set(LLamaLogCallback)
  </a>
  
    <nav class="md-nav" aria-label="llama_log_set(LLamaLogCallback)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#caution" class="md-nav__link">
    Caution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_self_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_self_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_self_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_initint32-int32-int32" class="md-nav__link">
    llama_batch_init(Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_init(Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_freellamanativebatch" class="md-nav__link">
    llama_batch_free(LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_free(LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_apply_adapter_cvecsafellamacontexthandle-single-uintptr-int32-int32-int32" class="md-nav__link">
    llama_apply_adapter_cvec(SafeLLamaContextHandle, Single*, UIntPtr, Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_apply_adapter_cvec(SafeLLamaContextHandle, Single*, UIntPtr, Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_split_pathstring-uintptr-string-int32-int32" class="md-nav__link">
    llama_split_path(String, UIntPtr, String, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_split_path(String, UIntPtr, String, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_split_prefixstring-uintptr-string-int32-int32" class="md-nav__link">
    llama_split_prefix(String, UIntPtr, String, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_split_prefix(String, UIntPtr, String, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_count" class="md-nav__link">
    ggml_backend_dev_count()
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_count()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_getuintptr" class="md-nav__link">
    ggml_backend_dev_get(UIntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_get(UIntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_buffer_typeintptr" class="md-nav__link">
    ggml_backend_dev_buffer_type(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_buffer_type(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_buft_nameintptr" class="md-nav__link">
    ggml_backend_buft_name(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_buft_name(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" class="md-nav__link">
    llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" class="md-nav__link">
    llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" class="md-nav__link">
    llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_freeintptr" class="md-nav__link">
    llava_image_embed_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" class="md-nav__link">
    llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getloadednativelibrarynativelibraryname" class="md-nav__link">
    GetLoadedNativeLibrary(NativeLibraryName)
  </a>
  
    <nav class="md-nav" aria-label="GetLoadedNativeLibrary(NativeLibraryName)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exceptions" class="md-nav__link">
    Exceptions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantizestring-string-llamamodelquantizeparams" class="md-nav__link">
    llama_model_quantize(String, String, LLamaModelQuantizeParams&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize(String, String, LLamaModelQuantizeParams&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.nativelibraryconfig/" class="md-nav__link">
        llama.native.nativelibraryconfig
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.ropescalingtype/" class="md-nav__link">
        llama.native.ropescalingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamacontexthandle/" class="md-nav__link">
        llama.native.safellamacontexthandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamagrammarhandle.md" class="md-nav__link">
        llama.native.safellamagrammarhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamahandlebase/" class="md-nav__link">
        llama.native.safellamahandlebase
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellamamodelhandle/" class="md-nav__link">
        llama.native.safellamamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellavaimageembedhandle/" class="md-nav__link">
        llama.native.safellavaimageembedhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.native.safellavamodelhandle/" class="md-nav__link">
        llama.native.safellavamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.quantizer.md" class="md-nav__link">
        llama.quantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.basesamplingpipeline/" class="md-nav__link">
        llama.sampling.basesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.defaultsamplingpipeline/" class="md-nav__link">
        llama.sampling.defaultsamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.greedysamplingpipeline/" class="md-nav__link">
        llama.sampling.greedysamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.isamplingpipeline/" class="md-nav__link">
        llama.sampling.isamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.isamplingpipelineextensions/" class="md-nav__link">
        llama.sampling.isamplingpipelineextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.mirostate2samplingpipeline.md" class="md-nav__link">
        llama.sampling.mirostate2samplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sampling.mirostatesamplingpipeline.md" class="md-nav__link">
        llama.sampling.mirostatesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.sessionstate/" class="md-nav__link">
        llama.sessionstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.streamingtokendecoder/" class="md-nav__link">
        llama.streamingtokendecoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletion.md" class="md-nav__link">
        llama.types.chatcompletion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchoice.md" class="md-nav__link">
        llama.types.chatcompletionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunk.md" class="md-nav__link">
        llama.types.chatcompletionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunkchoice.md" class="md-nav__link">
        llama.types.chatcompletionchunkchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionchunkdelta.md" class="md-nav__link">
        llama.types.chatcompletionchunkdelta
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatcompletionmessage.md" class="md-nav__link">
        llama.types.chatcompletionmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatmessagerecord.md" class="md-nav__link">
        llama.types.chatmessagerecord
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.chatrole.md" class="md-nav__link">
        llama.types.chatrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completion.md" class="md-nav__link">
        llama.types.completion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionchoice.md" class="md-nav__link">
        llama.types.completionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionchunk.md" class="md-nav__link">
        llama.types.completionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionlogprobs.md" class="md-nav__link">
        llama.types.completionlogprobs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.completionusage.md" class="md-nav__link">
        llama.types.completionusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embedding.md" class="md-nav__link">
        llama.types.embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embeddingdata.md" class="md-nav__link">
        llama.types.embeddingdata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../llama.types.embeddingusage.md" class="md-nav__link">
        llama.types.embeddingusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../logger.md" class="md-nav__link">
        logger
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama_empty_call" class="md-nav__link">
    llama_empty_call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_backend_free" class="md-nav__link">
    llama_backend_free()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_max_devices" class="md-nav__link">
    llama_max_devices()
  </a>
  
    <nav class="md-nav" aria-label="llama_max_devices()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mmap" class="md-nav__link">
    llama_supports_mmap()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mmap()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_mlock" class="md-nav__link">
    llama_supports_mlock()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_mlock()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_gpu_offload" class="md-nav__link">
    llama_supports_gpu_offload()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_gpu_offload()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_supports_rpc" class="md-nav__link">
    llama_supports_rpc()
  </a>
  
    <nav class="md-nav" aria-label="llama_supports_rpc()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_load_filesafellamacontexthandle-string-llamatoken-uint64-uint64" class="md-nav__link">
    llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_save_filesafellamacontexthandle-string-llamatoken-uint64" class="md-nav__link">
    llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_seq_save_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr" class="md-nav__link">
    llama_state_seq_save_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_seq_save_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_state_seq_load_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr-uintptr" class="md-nav__link">
    llama_state_seq_load_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr, UIntPtr&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_state_seq_load_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr, UIntPtr&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_causal_attnsafellamacontexthandle-boolean" class="md-nav__link">
    llama_set_causal_attn(SafeLLamaContextHandle, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_causal_attn(SafeLLamaContextHandle, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_embeddingssafellamacontexthandle-boolean" class="md-nav__link">
    llama_set_embeddings(SafeLLamaContextHandle, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_embeddings(SafeLLamaContextHandle, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_set_abort_callbacksafellamamodelhandle-intptr-intptr" class="md-nav__link">
    llama_set_abort_callback(SafeLlamaModelHandle, IntPtr, IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llama_set_abort_callback(SafeLlamaModelHandle, IntPtr, IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_n_seq_maxsafellamacontexthandle" class="md-nav__link">
    llama_n_seq_max(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_n_seq_max(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_get_embeddingssafellamacontexthandle" class="md-nav__link">
    llama_get_embeddings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_get_embeddings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_apply_templatebyte-llamachatmessage-uintptr-boolean-byte-int32" class="md-nav__link">
    llama_chat_apply_template(Byte, LLamaChatMessage, UIntPtr, Boolean, Byte*, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_apply_template(Byte, LLamaChatMessage, UIntPtr, Boolean, Byte*, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_chat_builtin_templateschar-uintptr" class="md-nav__link">
    llama_chat_builtin_templates(Char, UIntPtr)**
  </a>
  
    <nav class="md-nav" aria-label="llama_chat_builtin_templates(Char, UIntPtr)**">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_timingssafellamacontexthandle" class="md-nav__link">
    llama_print_timings(SafeLLamaContextHandle)
  </a>
  
    <nav class="md-nav" aria-label="llama_print_timings(SafeLLamaContextHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_print_system_info" class="md-nav__link">
    llama_print_system_info()
  </a>
  
    <nav class="md-nav" aria-label="llama_print_system_info()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_token_to_piecevocabulary-llamatoken-spanbyte-int32-boolean" class="md-nav__link">
    llama_token_to_piece(Vocabulary, LLamaToken, Span&lt;Byte&gt;, Int32, Boolean)
  </a>
  
    <nav class="md-nav" aria-label="llama_token_to_piece(Vocabulary, LLamaToken, Span<Byte>, Int32, Boolean)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_log_setllamalogcallback" class="md-nav__link">
    llama_log_set(LLamaLogCallback)
  </a>
  
    <nav class="md-nav" aria-label="llama_log_set(LLamaLogCallback)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#caution" class="md-nav__link">
    Caution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_kv_self_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" class="md-nav__link">
    llama_kv_self_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)
  </a>
  
    <nav class="md-nav" aria-label="llama_kv_self_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_initint32-int32-int32" class="md-nav__link">
    llama_batch_init(Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_init(Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_batch_freellamanativebatch" class="md-nav__link">
    llama_batch_free(LLamaNativeBatch)
  </a>
  
    <nav class="md-nav" aria-label="llama_batch_free(LLamaNativeBatch)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_apply_adapter_cvecsafellamacontexthandle-single-uintptr-int32-int32-int32" class="md-nav__link">
    llama_apply_adapter_cvec(SafeLLamaContextHandle, Single*, UIntPtr, Int32, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_apply_adapter_cvec(SafeLLamaContextHandle, Single*, UIntPtr, Int32, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_split_pathstring-uintptr-string-int32-int32" class="md-nav__link">
    llama_split_path(String, UIntPtr, String, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_split_path(String, UIntPtr, String, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_18" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_split_prefixstring-uintptr-string-int32-int32" class="md-nav__link">
    llama_split_prefix(String, UIntPtr, String, Int32, Int32)
  </a>
  
    <nav class="md-nav" aria-label="llama_split_prefix(String, UIntPtr, String, Int32, Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_19" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_count" class="md-nav__link">
    ggml_backend_dev_count()
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_count()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#returns_20" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_getuintptr" class="md-nav__link">
    ggml_backend_dev_get(UIntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_get(UIntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_21" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_dev_buffer_typeintptr" class="md-nav__link">
    ggml_backend_dev_buffer_type(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_dev_buffer_type(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_22" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ggml_backend_buft_nameintptr" class="md-nav__link">
    ggml_backend_buft_name(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="ggml_backend_buft_name(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_23" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" class="md-nav__link">
    llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)
  </a>
  
    <nav class="md-nav" aria-label="llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_24" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" class="md-nav__link">
    llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_25" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" class="md-nav__link">
    llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_26" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_image_embed_freeintptr" class="md-nav__link">
    llava_image_embed_free(IntPtr)
  </a>
  
    <nav class="md-nav" aria-label="llava_image_embed_free(IntPtr)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" class="md-nav__link">
    llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_27" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#getloadednativelibrarynativelibraryname" class="md-nav__link">
    GetLoadedNativeLibrary(NativeLibraryName)
  </a>
  
    <nav class="md-nav" aria-label="GetLoadedNativeLibrary(NativeLibraryName)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_28" class="md-nav__link">
    Returns
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exceptions" class="md-nav__link">
    Exceptions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama_model_quantizestring-string-llamamodelquantizeparams" class="md-nav__link">
    llama_model_quantize(String, String, LLamaModelQuantizeParams&amp;)
  </a>
  
    <nav class="md-nav" aria-label="llama_model_quantize(String, String, LLamaModelQuantizeParams&)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_29" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="./"><code>&lt; Back</code></a></p>
<hr />
<h1 id="nativeapi">NativeApi<a class="headerlink" href="#nativeapi" title="Permanent link"></a></h1>
<p>Namespace: LLama.Native</p>
<p>Direct translation of the llama.cpp API</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">NativeApi</span>
</code></pre></div></td></tr></table></div>
<p>Inheritance <a href="https://docs.microsoft.com/en-us/dotnet/api/system.object">Object</a>  <a href="./">NativeApi</a><br>
Attributes <a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.nullablecontextattribute">NullableContextAttribute</a>, <a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.nullableattribute">NullableAttribute</a></p>
<h2 id="methods">Methods<a class="headerlink" href="#methods" title="Permanent link"></a></h2>
<h3 id="llama_empty_call"><strong>llama_empty_call()</strong><a class="headerlink" href="#llama_empty_call" title="Permanent link"></a></h3>
<p>A method that does nothing. This is a native method, calling it will force the llama native dependencies to be loaded.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_empty_call</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h3 id="llama_backend_free"><strong>llama_backend_free()</strong><a class="headerlink" href="#llama_backend_free" title="Permanent link"></a></h3>
<p>Call once at the end of the program - currently only used for MPI</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_backend_free</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h3 id="llama_max_devices"><strong>llama_max_devices()</strong><a class="headerlink" href="#llama_max_devices" title="Permanent link"></a></h3>
<p>Get the maximum number of devices supported by llama.cpp</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="nf">llama_max_devices</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int64">Int64</a><br></p>
<h3 id="llama_supports_mmap"><strong>llama_supports_mmap()</strong><a class="headerlink" href="#llama_supports_mmap" title="Permanent link"></a></h3>
<p>Check if memory mapping is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_mmap</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_supports_mlock"><strong>llama_supports_mlock()</strong><a class="headerlink" href="#llama_supports_mlock" title="Permanent link"></a></h3>
<p>Check if memory locking is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_mlock</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_supports_gpu_offload"><strong>llama_supports_gpu_offload()</strong><a class="headerlink" href="#llama_supports_gpu_offload" title="Permanent link"></a></h3>
<p>Check if GPU offload is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_gpu_offload</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_supports_rpc"><strong>llama_supports_rpc()</strong><a class="headerlink" href="#llama_supports_rpc" title="Permanent link"></a></h3>
<p>Check if RPC offload is supported</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_supports_rpc</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_state_load_filesafellamacontexthandle-string-llamatoken-uint64-uint64"><strong>llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)</strong><a class="headerlink" href="#llama_state_load_filesafellamacontexthandle-string-llamatoken-uint64-uint64" title="Permanent link"></a></h3>
<p>Load session file</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_state_load_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">path_session</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="p">[]</span><span class="w"> </span><span class="n">tokens_out</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_token_capacity</span><span class="p">,</span><span class="w"> </span><span class="n">UInt64</span><span class="o">&amp;</span><span class="w"> </span><span class="n">n_token_count_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>path_session</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>tokens_out</code> <a href="../llama.native.llamatoken/">LLamaToken[]</a><br></p>
<p><code>n_token_capacity</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<p><code>n_token_count_out</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64&amp;">UInt64&amp;</a><br></p>
<h4 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_state_save_filesafellamacontexthandle-string-llamatoken-uint64"><strong>llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)</strong><a class="headerlink" href="#llama_state_save_filesafellamacontexthandle-string-llamatoken-uint64" title="Permanent link"></a></h3>
<p>Save session file</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_state_save_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">path_session</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="p">[]</span><span class="w"> </span><span class="n">tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">ulong</span><span class="w"> </span><span class="n">n_token_count</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>path_session</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>tokens</code> <a href="../llama.native.llamatoken/">LLamaToken[]</a><br></p>
<p><code>n_token_count</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint64">UInt64</a><br></p>
<h4 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_state_seq_save_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr"><strong>llama_state_seq_save_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr)</strong><a class="headerlink" href="#llama_state_seq_save_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr" title="Permanent link"></a></h3>
<p>Saves the specified sequence as a file on specified filepath. Can later be loaded via <a href="./#llama_state_load_filesafellamacontexthandle-string-llamatoken-uint64-uint64&amp;">NativeApi.llama_state_load_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64, UInt64&amp;)</a></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="nf">llama_state_seq_save_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq_id</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="o">*</span><span class="w"> </span><span class="n">tokens</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">n_token_count</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>filepath</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>seq_id</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>tokens</code> <a href="./llama.native.llamatoken*.md">LLamaToken*</a><br></p>
<p><code>n_token_count</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<h4 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<h3 id="llama_state_seq_load_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr-uintptr"><strong>llama_state_seq_load_file(SafeLLamaContextHandle, String, LLamaSeqId, LLamaToken*, UIntPtr, UIntPtr&amp;)</strong><a class="headerlink" href="#llama_state_seq_load_filesafellamacontexthandle-string-llamaseqid-llamatoken-uintptr-uintptr" title="Permanent link"></a></h3>
<p>Loads a sequence saved as a file via <a href="./#llama_state_save_filesafellamacontexthandle-string-llamatoken-uint64">NativeApi.llama_state_save_file(SafeLLamaContextHandle, String, LLamaToken[], UInt64)</a> into the specified sequence</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="nf">llama_state_seq_load_file</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">filepath</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">dest_seq_id</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="o">*</span><span class="w"> </span><span class="n">tokens_out</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">n_token_capacity</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="o">&amp;</span><span class="w"> </span><span class="n">n_token_count_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>filepath</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>dest_seq_id</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>tokens_out</code> <a href="./llama.native.llamatoken*.md">LLamaToken*</a><br></p>
<p><code>n_token_capacity</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<p><code>n_token_count_out</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr&amp;">UIntPtr&amp;</a><br></p>
<h4 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<h3 id="llama_set_causal_attnsafellamacontexthandle-boolean"><strong>llama_set_causal_attn(SafeLLamaContextHandle, Boolean)</strong><a class="headerlink" href="#llama_set_causal_attnsafellamacontexthandle-boolean" title="Permanent link"></a></h3>
<p>Set whether to use causal attention or not. If set to true, the model will only attend to the past tokens</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_set_causal_attn</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">causalAttn</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>causalAttn</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br></p>
<h3 id="llama_set_embeddingssafellamacontexthandle-boolean"><strong>llama_set_embeddings(SafeLLamaContextHandle, Boolean)</strong><a class="headerlink" href="#llama_set_embeddingssafellamacontexthandle-boolean" title="Permanent link"></a></h3>
<p>Set whether the model is in embeddings mode or not.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_set_embeddings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>embeddings</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
If true, embeddings will be returned but logits will not</p>
<h3 id="llama_set_abort_callbacksafellamamodelhandle-intptr-intptr"><strong>llama_set_abort_callback(SafeLlamaModelHandle, IntPtr, IntPtr)</strong><a class="headerlink" href="#llama_set_abort_callbacksafellamamodelhandle-intptr-intptr" title="Permanent link"></a></h3>
<p>Set abort callback</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_set_abort_callback</span><span class="p">(</span><span class="n">SafeLlamaModelHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="n">abortCallback</span><span class="p">,</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="n">abortCallbackData</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamamodelhandle/">SafeLlamaModelHandle</a><br></p>
<p><code>abortCallback</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<p><code>abortCallbackData</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_n_seq_maxsafellamacontexthandle"><strong>llama_n_seq_max(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_n_seq_maxsafellamacontexthandle" title="Permanent link"></a></h3>
<p>Get the n_seq_max for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="nf">llama_n_seq_max</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br></p>
<h3 id="llama_get_embeddingssafellamacontexthandle"><strong>llama_get_embeddings(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_get_embeddingssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Get all output token embeddings.
 When pooling_type == LLAMA_POOLING_TYPE_NONE or when using a generative model, the embeddings for which
 llama_batch.logits[i] != 0 are stored contiguously in the order they have appeared in the batch.
 shape: [n_outputs*n_embd]
 Otherwise, returns an empty span.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">llama_get_embeddings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h4 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>
<h3 id="llama_chat_apply_templatebyte-llamachatmessage-uintptr-boolean-byte-int32"><strong>llama_chat_apply_template(Byte<em>, LLamaChatMessage</em>, UIntPtr, Boolean, Byte*, Int32)</strong><a class="headerlink" href="#llama_chat_apply_templatebyte-llamachatmessage-uintptr-boolean-byte-int32" title="Permanent link"></a></h3>
<p>Apply chat template. Inspired by hf apply_chat_template() on python.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_chat_apply_template</span><span class="p">(</span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">tmpl</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaChatMessage</span><span class="o">*</span><span class="w"> </span><span class="n">chat</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">n_msg</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">add_ass</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="o">*</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">length</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link"></a></h4>
<p><code>tmpl</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br>
A Jinja template to use for this chat. If this is nullptr, the models default chat template will be used instead.</p>
<p><code>chat</code> <a href="./llama.native.llamachatmessage*.md">LLamaChatMessage*</a><br>
Pointer to a list of multiple llama_chat_message</p>
<p><code>n_msg</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br>
Number of llama_chat_message in this chat</p>
<p><code>add_ass</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
Whether to end the prompt with the token(s) that indicate the start of an assistant message.</p>
<p><code>buf</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte*">Byte*</a><br>
A buffer to hold the output formatted prompt. The recommended alloc size is 2 * (total number of characters of all messages)</p>
<p><code>length</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The size of the allocated buffer</p>
<h4 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The total number of bytes of the formatted prompt. If is it larger than the size of buffer, you may need to re-alloc it and then re-apply the template.</p>
<h3 id="llama_chat_builtin_templateschar-uintptr"><strong>llama_chat_builtin_templates(Char</strong>, UIntPtr)**<a class="headerlink" href="#llama_chat_builtin_templateschar-uintptr" title="Permanent link"></a></h3>
<p>Get list of built-in chat templates</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_chat_builtin_templates</span><span class="p">(</span><span class="n">Char</span><span class="o">**</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">len</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link"></a></h4>
<p><code>output</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.char**">Char**</a><br></p>
<p><code>len</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<h4 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_print_timingssafellamacontexthandle"><strong>llama_print_timings(SafeLLamaContextHandle)</strong><a class="headerlink" href="#llama_print_timingssafellamacontexthandle" title="Permanent link"></a></h3>
<p>Print out timing information for this context</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_print_timings</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<h3 id="llama_print_system_info"><strong>llama_print_system_info()</strong><a class="headerlink" href="#llama_print_system_info" title="Permanent link"></a></h3>
<p>Print system information</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">llama_print_system_info</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br></p>
<h3 id="llama_token_to_piecevocabulary-llamatoken-spanbyte-int32-boolean"><strong>llama_token_to_piece(Vocabulary, LLamaToken, Span&lt;Byte&gt;, Int32, Boolean)</strong><a class="headerlink" href="#llama_token_to_piecevocabulary-llamatoken-spanbyte-int32-boolean" title="Permanent link"></a></h3>
<p>Convert a single token into text</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_token_to_piece</span><span class="p">(</span><span class="n">Vocabulary</span><span class="w"> </span><span class="n">vocab</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaToken</span><span class="w"> </span><span class="n">llamaToken</span><span class="p">,</span><span class="w"> </span><span class="n">Span</span><span class="o">&lt;</span><span class="kt">byte</span><span class="o">&gt;</span><span class="w"> </span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lstrip</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">special</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link"></a></h4>
<p><code>vocab</code> <a href="./llama.native.safellamamodelhandle.vocabulary.md">Vocabulary</a><br></p>
<p><code>llamaToken</code> <a href="../llama.native.llamatoken/">LLamaToken</a><br></p>
<p><code>buffer</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.span-1">Span&lt;Byte&gt;</a><br>
buffer to write string into</p>
<p><code>lstrip</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
User can skip up to 'lstrip' leading spaces before copying (useful when encoding/decoding multiple tokens with 'add_space_prefix')</p>
<p><code>special</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
If true, special tokens are rendered in the output</p>
<h4 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
The length written, or if the buffer is too small a negative that indicates the length required</p>
<h3 id="llama_log_setllamalogcallback"><strong>llama_log_set(LLamaLogCallback)</strong><a class="headerlink" href="#llama_log_setllamalogcallback" title="Permanent link"></a></h3>
<h4 id="caution">Caution<a class="headerlink" href="#caution" title="Permanent link"></a></h4>
<p>Use <code>NativeLogConfig.llama_log_set</code> instead</p>
<hr />
<p>Register a callback to receive llama log messages</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_log_set</span><span class="p">(</span><span class="n">LLamaLogCallback</span><span class="w"> </span><span class="n">logCallback</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link"></a></h4>
<p><code>logCallback</code> <a href="./llama.native.nativelogconfig.llamalogcallback.md">LLamaLogCallback</a><br></p>
<h3 id="llama_kv_self_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos"><strong>llama_kv_self_seq_rm(SafeLLamaContextHandle, LLamaSeqId, LLamaPos, LLamaPos)</strong><a class="headerlink" href="#llama_kv_self_seq_rmsafellamacontexthandle-llamaseqid-llamapos-llamapos" title="Permanent link"></a></h3>
<p>Removes all tokens that belong to the specified sequence and have positions in [p0, p1)</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llama_kv_self_seq_rm</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaSeqId</span><span class="w"> </span><span class="n">seq</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p0</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaPos</span><span class="w"> </span><span class="n">p1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>seq</code> <a href="../llama.native.llamaseqid/">LLamaSeqId</a><br></p>
<p><code>p0</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<p><code>p1</code> <a href="../llama.native.llamapos/">LLamaPos</a><br></p>
<h4 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
Returns false if a partial sequence cannot be removed. Removing a whole sequence never fails</p>
<h3 id="llama_batch_initint32-int32-int32"><strong>llama_batch_init(Int32, Int32, Int32)</strong><a class="headerlink" href="#llama_batch_initint32-int32-int32" title="Permanent link"></a></h3>
<p>Allocates a batch of tokens on the heap
 Each token can be assigned up to n_seq_max sequence ids
 The batch has to be freed with llama_batch_free()
 If embd != 0, llama_batch.embd will be allocated with size of n_tokens * embd * sizeof(float)
 Otherwise, llama_batch.token will be allocated to store n_tokens llama_token
 The rest of the llama_batch members are allocated with size n_tokens
 All members are left uninitialized</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">LLamaNativeBatch</span><span class="w"> </span><span class="nf">llama_batch_init</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n_tokens</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">embd</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_seq_max</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link"></a></h4>
<p><code>n_tokens</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>embd</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>n_seq_max</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Each token can be assigned up to n_seq_max sequence ids</p>
<h4 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link"></a></h4>
<p><a href="../llama.native.llamanativebatch/">LLamaNativeBatch</a><br></p>
<h3 id="llama_batch_freellamanativebatch"><strong>llama_batch_free(LLamaNativeBatch)</strong><a class="headerlink" href="#llama_batch_freellamanativebatch" title="Permanent link"></a></h3>
<p>Frees a batch of tokens allocated with llama_batch_init()</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llama_batch_free</span><span class="p">(</span><span class="n">LLamaNativeBatch</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link"></a></h4>
<p><code>batch</code> <a href="../llama.native.llamanativebatch/">LLamaNativeBatch</a><br></p>
<h3 id="llama_apply_adapter_cvecsafellamacontexthandle-single-uintptr-int32-int32-int32"><strong>llama_apply_adapter_cvec(SafeLLamaContextHandle, Single*, UIntPtr, Int32, Int32, Int32)</strong><a class="headerlink" href="#llama_apply_adapter_cvecsafellamacontexthandle-single-uintptr-int32-int32-int32" title="Permanent link"></a></h3>
<p>Apply a loaded control vector to a llama_context, or if data is NULL, clear
 the currently loaded vector.
 n_embd should be the size of a single layer's control, and data should point
 to an n_embd x n_layers buffer starting from layer 1.
 il_start and il_end are the layer range the vector should apply to (both inclusive)
 See llama_control_vector_load in common to load a control vector.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_apply_adapter_cvec</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx</span><span class="p">,</span><span class="w"> </span><span class="n">Single</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">len</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_embd</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">il_start</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">il_end</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link"></a></h4>
<p><code>ctx</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br></p>
<p><code>data</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.single*">Single*</a><br></p>
<p><code>len</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<p><code>n_embd</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>il_start</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>il_end</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h3 id="llama_split_pathstring-uintptr-string-int32-int32"><strong>llama_split_path(String, UIntPtr, String, Int32, Int32)</strong><a class="headerlink" href="#llama_split_pathstring-uintptr-string-int32-int32" title="Permanent link"></a></h3>
<p>Build a split GGUF final path for this chunk.
 llama_split_path(split_path, sizeof(split_path), "/models/ggml-model-q4_0", 2, 4) =&gt; split_path = "/models/ggml-model-q4_0-00002-of-00004.gguf"</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_split_path</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">split_path</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">maxlen</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">path_prefix</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">split_no</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">split_count</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link"></a></h4>
<p><code>split_path</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>maxlen</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<p><code>path_prefix</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>split_no</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>split_count</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_18">Returns<a class="headerlink" href="#returns_18" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Returns the split_path length.</p>
<h3 id="llama_split_prefixstring-uintptr-string-int32-int32"><strong>llama_split_prefix(String, UIntPtr, String, Int32, Int32)</strong><a class="headerlink" href="#llama_split_prefixstring-uintptr-string-int32-int32" title="Permanent link"></a></h3>
<p>Extract the path prefix from the split_path if and only if the split_no and split_count match.
 llama_split_prefix(split_prefix, 64, "/models/ggml-model-q4_0-00002-of-00004.gguf", 2, 4) =&gt; split_prefix = "/models/ggml-model-q4_0"</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">llama_split_prefix</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">split_prefix</span><span class="p">,</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">maxlen</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">split_path</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">split_no</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">split_count</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link"></a></h4>
<p><code>split_prefix</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>maxlen</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br></p>
<p><code>split_path</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>split_no</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>split_count</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<h4 id="returns_19">Returns<a class="headerlink" href="#returns_19" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Returns the split_prefix length.</p>
<h3 id="ggml_backend_dev_count"><strong>ggml_backend_dev_count()</strong><a class="headerlink" href="#ggml_backend_dev_count" title="Permanent link"></a></h3>
<p>Get the number of available backend devices</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">UIntPtr</span><span class="w"> </span><span class="nf">ggml_backend_dev_count</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<h4 id="returns_20">Returns<a class="headerlink" href="#returns_20" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br>
Count of available backend devices</p>
<h3 id="ggml_backend_dev_getuintptr"><strong>ggml_backend_dev_get(UIntPtr)</strong><a class="headerlink" href="#ggml_backend_dev_getuintptr" title="Permanent link"></a></h3>
<p>Get a backend device by index</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">ggml_backend_dev_get</span><span class="p">(</span><span class="n">UIntPtr</span><span class="w"> </span><span class="n">i</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link"></a></h4>
<p><code>i</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.uintptr">UIntPtr</a><br>
Device index</p>
<h4 id="returns_21">Returns<a class="headerlink" href="#returns_21" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Pointer to the backend device</p>
<h3 id="ggml_backend_dev_buffer_typeintptr"><strong>ggml_backend_dev_buffer_type(IntPtr)</strong><a class="headerlink" href="#ggml_backend_dev_buffer_typeintptr" title="Permanent link"></a></h3>
<p>Get the buffer type for a backend device</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">ggml_backend_dev_buffer_type</span><span class="p">(</span><span class="n">IntPtr</span><span class="w"> </span><span class="n">dev</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link"></a></h4>
<p><code>dev</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Backend device pointer</p>
<h4 id="returns_22">Returns<a class="headerlink" href="#returns_22" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Pointer to the buffer type</p>
<h3 id="ggml_backend_buft_nameintptr"><strong>ggml_backend_buft_name(IntPtr)</strong><a class="headerlink" href="#ggml_backend_buft_nameintptr" title="Permanent link"></a></h3>
<p>Get the name of a buffer type</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">IntPtr</span><span class="w"> </span><span class="nf">ggml_backend_buft_name</span><span class="p">(</span><span class="n">IntPtr</span><span class="w"> </span><span class="n">buft</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link"></a></h4>
<p><code>buft</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Buffer type pointer</p>
<h4 id="returns_23">Returns<a class="headerlink" href="#returns_23" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Name of the buffer type</p>
<h3 id="llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle"><strong>llava_validate_embed_size(SafeLLamaContextHandle, SafeLlavaModelHandle)</strong><a class="headerlink" href="#llava_validate_embed_sizesafellamacontexthandle-safellavamodelhandle" title="Permanent link"></a></h3>
<p>Sanity check for clip &lt;-&gt; llava embed size match</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llava_validate_embed_size</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctxLlama</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctxClip</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link"></a></h4>
<p><code>ctxLlama</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br>
LLama Context</p>
<p><code>ctxClip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
Llava Model</p>
<h4 id="returns_24">Returns<a class="headerlink" href="#returns_24" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
True if validate successfully</p>
<h3 id="llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32"><strong>llava_image_embed_make_with_bytes(SafeLlavaModelHandle, Int32, Byte[], Int32)</strong><a class="headerlink" href="#llava_image_embed_make_with_bytessafellavamodelhandle-int32-byte-int32" title="Permanent link"></a></h3>
<p>Build an image embed from image file bytes</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="nf">llava_image_embed_make_with_bytes</span><span class="p">(</span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctx_clip</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_threads</span><span class="p">,</span><span class="w"> </span><span class="n">Byte</span><span class="p">[]</span><span class="w"> </span><span class="n">image_bytes</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">image_bytes_length</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link"></a></h4>
<p><code>ctx_clip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
SafeHandle to the Clip Model</p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of threads</p>
<p><code>image_bytes</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.byte">Byte[]</a><br>
Binary image in jpeg format</p>
<p><code>image_bytes_length</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Bytes length of the image</p>
<h4 id="returns_25">Returns<a class="headerlink" href="#returns_25" title="Permanent link"></a></h4>
<p><a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
SafeHandle to the Embeddings</p>
<h3 id="llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string"><strong>llava_image_embed_make_with_filename(SafeLlavaModelHandle, Int32, String)</strong><a class="headerlink" href="#llava_image_embed_make_with_filenamesafellavamodelhandle-int32-string" title="Permanent link"></a></h3>
<p>Build an image embed from a path to an image filename</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="nf">llava_image_embed_make_with_filename</span><span class="p">(</span><span class="n">SafeLlavaModelHandle</span><span class="w"> </span><span class="n">ctx_clip</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_threads</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">image_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link"></a></h4>
<p><code>ctx_clip</code> <a href="../llama.native.safellavamodelhandle/">SafeLlavaModelHandle</a><br>
SafeHandle to the Clip Model</p>
<p><code>n_threads</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br>
Number of threads</p>
<p><code>image_path</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br>
Image filename (jpeg) to generate embeddings</p>
<h4 id="returns_26">Returns<a class="headerlink" href="#returns_26" title="Permanent link"></a></h4>
<p><a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
SafeHandle to the embeddings</p>
<h3 id="llava_image_embed_freeintptr"><strong>llava_image_embed_free(IntPtr)</strong><a class="headerlink" href="#llava_image_embed_freeintptr" title="Permanent link"></a></h3>
<p>Free an embedding made with llava_image_embed_make_*</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">llava_image_embed_free</span><span class="p">(</span><span class="n">IntPtr</span><span class="w"> </span><span class="n">embed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link"></a></h4>
<p><code>embed</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.intptr">IntPtr</a><br>
Embeddings to release</p>
<h3 id="llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32"><strong>llava_eval_image_embed(SafeLLamaContextHandle, SafeLlavaImageEmbedHandle, Int32, Int32&amp;)</strong><a class="headerlink" href="#llava_eval_image_embedsafellamacontexthandle-safellavaimageembedhandle-int32-int32" title="Permanent link"></a></h3>
<p>Write the image represented by embed into the llama context with batch size n_batch, starting at context
 pos n_past. on completion, n_past points to the next position in the context after the image embed.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">llava_eval_image_embed</span><span class="p">(</span><span class="n">SafeLLamaContextHandle</span><span class="w"> </span><span class="n">ctx_llama</span><span class="p">,</span><span class="w"> </span><span class="n">SafeLlavaImageEmbedHandle</span><span class="w"> </span><span class="n">embed</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_batch</span><span class="p">,</span><span class="w"> </span><span class="n">Int32</span><span class="o">&amp;</span><span class="w"> </span><span class="n">n_past</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link"></a></h4>
<p><code>ctx_llama</code> <a href="../llama.native.safellamacontexthandle/">SafeLLamaContextHandle</a><br>
Llama Context</p>
<p><code>embed</code> <a href="../llama.native.safellavaimageembedhandle/">SafeLlavaImageEmbedHandle</a><br>
Embedding handle</p>
<p><code>n_batch</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32">Int32</a><br></p>
<p><code>n_past</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.int32&amp;">Int32&amp;</a><br></p>
<h4 id="returns_27">Returns<a class="headerlink" href="#returns_27" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.boolean">Boolean</a><br>
True on success</p>
<h3 id="getloadednativelibrarynativelibraryname"><strong>GetLoadedNativeLibrary(NativeLibraryName)</strong><a class="headerlink" href="#getloadednativelibrarynativelibraryname" title="Permanent link"></a></h3>
<p>Get the loaded native library. If you are using netstandard2.0, it will always return null.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="n">INativeLibrary</span><span class="w"> </span><span class="nf">GetLoadedNativeLibrary</span><span class="p">(</span><span class="n">NativeLibraryName</span><span class="w"> </span><span class="n">name</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link"></a></h4>
<p><code>name</code> <a href="../llama.native.nativelibraryname/">NativeLibraryName</a><br></p>
<h4 id="returns_28">Returns<a class="headerlink" href="#returns_28" title="Permanent link"></a></h4>
<p><a href="../llama.abstractions.inativelibrary/">INativeLibrary</a><br></p>
<h4 id="exceptions">Exceptions<a class="headerlink" href="#exceptions" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.argumentexception">ArgumentException</a><br></p>
<h3 id="llama_model_quantizestring-string-llamamodelquantizeparams"><strong>llama_model_quantize(String, String, LLamaModelQuantizeParams&amp;)</strong><a class="headerlink" href="#llama_model_quantizestring-string-llamamodelquantizeparams" title="Permanent link"></a></h3>
<p>Returns 0 on success</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint</span><span class="w"> </span><span class="nf">llama_model_quantize</span><span class="p">(</span><span class="kt">string</span><span class="w"> </span><span class="n">fname_inp</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="n">fname_out</span><span class="p">,</span><span class="w"> </span><span class="n">LLamaModelQuantizeParams</span><span class="o">&amp;</span><span class="w"> </span><span class="n">param</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h4 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link"></a></h4>
<p><code>fname_inp</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>fname_out</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.string">String</a><br></p>
<p><code>param</code> <a href="./llama.native.llamamodelquantizeparams&amp;.md">LLamaModelQuantizeParams&amp;</a><br></p>
<h4 id="returns_29">Returns<a class="headerlink" href="#returns_29" title="Permanent link"></a></h4>
<p><a href="https://docs.microsoft.com/en-us/dotnet/api/system.uint32">UInt32</a><br>
Returns 0 on success</p>
<hr />
<p><a href="./"><code>&lt; Back</code></a></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "navigation.instant"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>